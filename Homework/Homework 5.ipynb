{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5\n",
    "\n",
    "## by Dion Ho\n",
    "\n",
    "\n",
    "# Import Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import scipy\n",
    "from scipy import linalg as la\n",
    "from scipy import sparse\n",
    "from math import pi\n",
    "from math import factorial\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rangeE(start,end): #I really dislike Python's range function, so I defined my own in line with other languages.\n",
    "    return range(start,end+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $\\lVert\\vec{x}\\rVert_\\infty = 1, \\forall x_j \\in \\vec{x}, -1 \\leq \\vec{x_j} \\leq 1$.\n",
    "Each entry, $b_i$, of vector $(A\\vec{x})$ is given by\n",
    "$$b_i = \\sum_{j=1}^n x_j a_{i,j}.$$\n",
    "In order to maximise $b_i$, we choose\n",
    "$$\\begin{cases}\n",
    "x_j = 1 & \\mbox{if } a_{i,j} \\geq 0 \\\\\n",
    "x_j = -1 & \\mbox{if } a_{i,j} < 0.\n",
    "\\end{cases}\n",
    "$$\n",
    "Therefore, \n",
    "$$\\max\\limits_{\\lVert\\vec{x}\\rVert_\\infty = 1}b_i = \\sum_{j=1}^n |a_{i,j}|$$\n",
    "which implies that \n",
    "\\begin{align}\n",
    "\\lVert A \\rVert_\\infty &= \\max\\limits_{\\lVert\\vec{x}\\rVert_\\infty = 1} \\lVert A\\vec{x} \\rVert_\\infty \\\\\n",
    "&= \\max\\limits_{1 \\leq i \\leq n} \\sum_{j=1}^n |a_{i,j}|.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the sequence $\\left (\\vec{x}^{\\left (k\\right )}\\right )_{k \\in \\mathbb{N}^0}$ converges, it must be Cauchy. Therefore, for an arbitrary $\\vec{x}^{\\left (0\\right )} \\in \\mathbb{R}^n$, for all $\\epsilon z > 0$, where $z = \\left \\lVert \\vec{x}^{\\left (1\\right )} - \\vec{x}^{\\left (0\\right )} \\right \\rVert, \\exists K \\in \\mathbb{N}^0$ such that $\\forall m,k \\geq K$, \n",
    "$$\\left \\lVert \\vec{x}^{\\left (m\\right )} - \\vec{x}^{\\left (k\\right )} \\right \\rVert< \\epsilon z.$$\n",
    "In particular, $\\forall k \\geq K$,\n",
    "\\begin{align}\n",
    "&\\left \\lVert \\vec{x}^{\\left (k+1\\right )} - \\vec{x}^{\\left (k\\right )} \\right \\rVert < \\epsilon z \\\\\n",
    "&\\implies \\left \\lVert T\\vec{x}^{\\left (k\\right )} + \\vec{c} - T\\vec{x}^{\\left (k-1\\right )} - \\vec{c} \\right \\rVert < \\epsilon z \\\\\n",
    "&\\implies \\left \\lVert T\\left (\\vec{x}^{\\left (k\\right )} - \\vec{x}^{\\left (k-1\\right )}\\right ) \\right \\rVert < \\epsilon z \\\\\n",
    "&\\implies \\left \\lVert T\\left (T\\vec{x}^{\\left (k-1\\right )} + \\vec{c} - T\\vec{x}^{\\left (k-2\\right )} - \\vec{c}\\right ) \\right \\rVert < \\epsilon z \\\\\n",
    "&\\implies \\left \\lVert T^2\\left (\\vec{x}^{\\left (k-1\\right )} - \\vec{x}^{\\left (k-2\\right )}\\right ) \\right \\rVert < \\epsilon z \\\\\n",
    "&\\implies \\ldots \\\\\n",
    "&\\implies \\left \\lVert T^k \\left (\\vec{x}^{\\left (1\\right )} - \\vec{x}^{\\left (0\\right )}\\right ) \\right \\rVert < \\epsilon z \\\\\n",
    "&\\implies \\left \\lVert T^k \\right \\rVert \\left \\lVert \\vec{x}^{\\left (1\\right )} - \\vec{x}^{\\left (0\\right )} \\right \\rVert \\leq \\left \\lVert T^k \\left (\\vec{x}^{\\left (1\\right )} - \\vec{x}^{\\left (0\\right )}\\right ) \\right \\rVert < \\epsilon z \\\\\n",
    "&\\implies \\left \\lVert T^k \\right \\rVert < \\epsilon.\n",
    "\\end{align}\n",
    "Therefore, $\\lim\\limits_{k\\rightarrow\\infty}T^k = 0_{nxn}$ which implies that $\\rho\\left (T\\right ) < 1$ by property of the spectral radius."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacobian_iteration(A,b,x1,tol=1e-8,maxiter=100):\n",
    "    if A.shape[0] != A.shape[1]:\n",
    "        return \"Error, matrix is not square.\"\n",
    "    m = A.shape[1]\n",
    "    b.shape = (m,)\n",
    "    x1.shape = (m,)\n",
    "    D = np.diag(np.diag(A))\n",
    "    AA = A - D\n",
    "    D_inv = np.diag(1/np.diag(A))\n",
    "    x = D_inv @ (b - (AA @ x1))\n",
    "    iteration = 1\n",
    "    residue = la.norm((x1 - x),np.inf)\n",
    "    print(\"iter\",\"   residue\")\n",
    "    print('{:>3d} {:> 22.16f}'.format(iteration, residue))\n",
    "    while (residue > tol) & (maxiter >= iteration):\n",
    "        x1 = x\n",
    "        x = D_inv @ (b - (AA @ x1))\n",
    "        residue = la.norm((x1 - x),np.inf)\n",
    "        iteration += 1\n",
    "        print('{:>3d} {:> 22.16f}'.format(iteration, residue))\n",
    "    if maxiter >= iteration + 1:\n",
    "        return x\n",
    "    else:\n",
    "        print(\"Failed to converge.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diag_dom(n, num_entries=None):\n",
    "    if num_entries is None:\n",
    "        num_entries = int(n**1.5) - n\n",
    "    A = np.zeros((n,n))\n",
    "    rows = np.random.choice(np.arange(0,n), size=num_entries)\n",
    "    cols = np.random.choice(np.arange(0,n), size=num_entries)\n",
    "    data = np.random.randint(-4, 4, size=num_entries)\n",
    "    for i in range(num_entries):\n",
    "        A[rows[i], cols[i]] = data[i]\n",
    "    for i in range(n):\n",
    "        A[i,i] = np.sum(np.abs(A[i])) + 1\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to generate the randomised test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = np.random.randint(2,20)\n",
    "x = np.random.rand(size,1)\n",
    "A = diag_dom(size)\n",
    "b = A @ x\n",
    "x1 = np.random.rand(size,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter    residue\n",
      "  1     0.3189834692606852\n",
      "  2     0.0000000000000000\n",
      "[0.16963229 0.74495377 0.20145741] True\n"
     ]
    }
   ],
   "source": [
    "ans = jacobian_iteration(A,b,x1)\n",
    "print(ans,np.allclose(ans.reshape(len(ans),), x.reshape(len(x),))) #jacobian_iteration works even for random A, x, and initial guess x1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacobian_iteration_plot(A,b,x1,plot = False,tol=1e-8,maxiter=100):\n",
    "    if A.shape[0] != A.shape[1]:\n",
    "        return \"Error, matrix is not square.\"\n",
    "    m = A.shape[1]\n",
    "    b.shape = (m,)\n",
    "    x1.shape = (m,)\n",
    "    D = np.diag(np.diag(A))\n",
    "    AA = A - D\n",
    "    D_inv = np.diag(1/np.diag(A))\n",
    "    x = D_inv @ (b - (AA @ x1))\n",
    "    iteration = 1\n",
    "    residue = la.norm((x1 - x),np.inf)\n",
    "    if plot == True:\n",
    "        res_plt = [residue]\n",
    "    else:\n",
    "        print(\"iter\",\"   residue\")\n",
    "        print('{:>3d} {:> 22.16f}'.format(iteration, residue))\n",
    "    while (residue > tol) & (maxiter >= iteration):\n",
    "        x1 = x\n",
    "        x = D_inv @ (b - (AA @ x1))\n",
    "        residue = la.norm((x1 - x),np.inf)\n",
    "        iteration += 1\n",
    "        if plot == True:\n",
    "            res_plt.append(residue)\n",
    "        else:\n",
    "            print('{:>3d} {:> 22.16f}'.format(iteration, residue))\n",
    "    if plot == True:\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.semilogy(rangeE(1,iteration),np.abs(res_plt),'o')\n",
    "        plt.title('Plot of Residue for Jacobian Iteration against Iteration Count',fontsize=18)\n",
    "        plt.xlabel('Iteration Count',fontsize=14)\n",
    "        plt.ylabel('Residue',fontsize=14)\n",
    "    if maxiter >= iteration + 1:\n",
    "        return x\n",
    "    else:\n",
    "        print(\"Failed to converge.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to generate the randomised test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = np.random.randint(3,20)\n",
    "x = np.random.rand(size,1)\n",
    "A = diag_dom(size)\n",
    "b = A @ x\n",
    "x1 = np.random.rand(size,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = jacobian_iteration_plot(A,b,x1,True)\n",
    "print(ans,np.allclose(ans, x)) #The plot shows that the log of the residue decreases about linearly as the number of iterations increase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5: With the addition of tuning parameter $\\omega$ which defaults to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_seidel_plot(A,b,x1,plot=False,tol=1e-8,maxiter=100,omega=1):\n",
    "    if A.shape[0] != A.shape[1]:\n",
    "        return \"Error, matrix is not square.\"\n",
    "    m = A.shape[1]\n",
    "    b.shape = (m,)\n",
    "    x1.shape = (m,)\n",
    "    x = np.zeros(np.shape(b))\n",
    "    for ii in rangeE(0,m-1):\n",
    "        sum1 = 0\n",
    "        sum2 = 0\n",
    "        for jj in rangeE(0,ii-1):\n",
    "            sum1 += A[ii,jj]*x[jj]\n",
    "        for jj in rangeE(ii,m-1): #Without omega, this is rangeE(ii+1,m-1)\n",
    "            sum2 += A[ii,jj]*x1[jj]\n",
    "        x[ii] = x1[ii] + omega*(b[ii] - sum1 - sum2)/A[ii,ii]\n",
    "    iteration = 1\n",
    "    residue = la.norm((x1 - x),np.inf)\n",
    "    if plot == True:\n",
    "        res_plt = [residue]\n",
    "    else:\n",
    "        print(\"iter\",\"   residue\")\n",
    "        print('{:>3d} {:> 22.16f}'.format(iteration, residue))\n",
    "    while (residue > tol) & (maxiter >= iteration):\n",
    "        x1 = np.copy(x)\n",
    "        for ii in rangeE(0,m-1):\n",
    "            sum1 = 0\n",
    "            sum2 = 0\n",
    "            for jj in rangeE(0,ii-1):\n",
    "                sum1 += A[ii,jj]*x[jj]\n",
    "            for jj in rangeE(ii,m-1):\n",
    "                sum2 += A[ii,jj]*x1[jj]\n",
    "            x[ii] = x1[ii] + omega*(b[ii] - sum1 - sum2)/A[ii,ii]\n",
    "        residue = la.norm((x1 - x),np.inf)\n",
    "        iteration += 1\n",
    "        if plot == True:\n",
    "            res_plt.append(residue)\n",
    "        else:\n",
    "            print('{:>3d} {:> 22.16f}'.format(iteration, residue))\n",
    "    if plot == True:\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.semilogy(rangeE(1,iteration),np.abs(res_plt),'o')\n",
    "        plt.title('Plot of Residue for Gauss-Seidel Method against Iteration Count',fontsize=18)\n",
    "        plt.xlabel('Iteration Count',fontsize=14)\n",
    "        plt.ylabel('Residue',fontsize=14)\n",
    "    if maxiter >= iteration + 1:\n",
    "        return x\n",
    "    else:\n",
    "        print(\"Failed to converge.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to generate the randomised test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = np.random.randint(3,20)\n",
    "x = np.random.rand(size,1)\n",
    "A = diag_dom(size)\n",
    "b = A @ x\n",
    "x1 = np.random.rand(size,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = gauss_seidel_plot(A,b,x1,True)\n",
    "print(ans,np.allclose(ans, x)) #The plot shows that the log of the residue decreases about linearly as the number of iterations increase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6 & Q7: Gauss-Seidel with the addition of tuning parameter $\\omega$ which defaults to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_seidel_plot_sparse(A,b,x1,plot=False,tol=1e-8,maxiter=100,omega=1):\n",
    "    if A.shape[0] != A.shape[1]:\n",
    "        return \"Error, matrix is not square.\"\n",
    "    m = A.shape[1]\n",
    "    b.shape = (m,)\n",
    "    x1.shape = (m,)\n",
    "    x = np.zeros(np.shape(b))\n",
    "    D = sparse.diags(A.diagonal())\n",
    "    AA = A - D\n",
    "    for ii in rangeE(0,m-1):\n",
    "        rowstart = AA.indptr[ii]\n",
    "        rowend = AA.indptr[ii+1]\n",
    "        Aix = AA.data[rowstart:rowend] @ x1[A.indices[rowstart:rowend]]\n",
    "        x[ii] = (1-omega)*x1[ii] + omega*(b[ii] - Aix)/A[ii,ii]\n",
    "    iteration = 1\n",
    "    residue = la.norm((x1 - x),np.inf)\n",
    "    if plot == True:\n",
    "        res_plt = [residue]\n",
    "    else:\n",
    "        print(\"iter\",\"   residue\")\n",
    "        print('{:>3d} {:> 22.16f}'.format(iteration, residue))\n",
    "    while (residue > tol) & (maxiter >= iteration):\n",
    "        x1 = np.copy(x)\n",
    "        for ii in rangeE(0,m-1):\n",
    "            rowstart = AA.indptr[ii]\n",
    "            rowend = AA.indptr[ii+1]\n",
    "            Aix = AA.data[rowstart:rowend] @ x1[AA.indices[rowstart:rowend]]\n",
    "            x[ii] = (1-omega)*x1[ii] + omega*(b[ii] - Aix)/A[ii,ii]\n",
    "        residue = la.norm((x1 - x),np.inf)\n",
    "        iteration += 1\n",
    "        if plot == True:\n",
    "            res_plt.append(residue)\n",
    "        else:\n",
    "            print('{:>3d} {:> 22.16f}'.format(iteration, residue))\n",
    "    if plot == True:\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.semilogy(rangeE(1,iteration),np.abs(res_plt),'o')\n",
    "        plt.title('Plot of Residue for Gauss-Seidel Method against Iteration Count',fontsize=18)\n",
    "        plt.xlabel('Iteration Count',fontsize=14)\n",
    "        plt.ylabel('Residue',fontsize=14)\n",
    "    if maxiter >= iteration + 1:\n",
    "        return x\n",
    "    else:\n",
    "        print(\"Failed to converge.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diag_dom_sparse(n, num_entries=None):\n",
    "    if num_entries is None:\n",
    "        num_entries = int(n**1.5) - n\n",
    "    rows = np.random.choice(np.arange(0,n), size=num_entries)\n",
    "    cols = np.random.choice(np.arange(0,n), size=num_entries)\n",
    "    data = np.random.randint(-4, 4, size=num_entries)\n",
    "    A = sparse.csr_matrix((data, (rows,cols)), shape=(n,n))\n",
    "    d = []\n",
    "    for i in range(n):\n",
    "        d.append(np.sum(np.abs(A[i])) + 1)\n",
    "    A.setdiag(d)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dionh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\scipy\\sparse\\compressed.py:708: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self[i, j] = values\n"
     ]
    }
   ],
   "source": [
    "size = np.random.randint(5000,15000)\n",
    "x = np.random.rand(size,1)\n",
    "x.shape=(size,)\n",
    "A = diag_dom_sparse(size) #Generation of the sparse matrix may take about a minute.\n",
    "b = A @ x\n",
    "x1 = np.random.rand(size,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter    residue\n",
      "  1     1.6211828644261368\n",
      "  2     1.0814543409812978\n",
      "  3     0.6682127877062565\n",
      "  4     0.4138431535906028\n",
      "  5     0.2932435270609431\n",
      "  6     0.1983766915404211\n",
      "  7     0.1292259979360931\n",
      "  8     0.0914851444299374\n",
      "  9     0.0632694287006306\n",
      " 10     0.0426529501929498\n",
      " 11     0.0282356594854396\n",
      " 12     0.0189448850996428\n",
      " 13     0.0129344234079372\n",
      " 14     0.0087190471817860\n",
      " 15     0.0058890032482547\n",
      " 16     0.0039644293823403\n",
      " 17     0.0026488894873469\n",
      " 18     0.0018213729583426\n",
      " 19     0.0012413264062306\n",
      " 20     0.0008494353840393\n",
      " 21     0.0005857600445137\n",
      " 22     0.0003993364231445\n",
      " 23     0.0002752790600370\n",
      " 24     0.0001916607769230\n",
      " 25     0.0001322322792952\n",
      " 26     0.0000904934860086\n",
      " 27     0.0000616627177045\n",
      " 28     0.0000427639600682\n",
      " 29     0.0000293722901618\n",
      " 30     0.0000199896277912\n",
      " 31     0.0000134851735635\n",
      " 32     0.0000090208437430\n",
      " 33     0.0000059855910045\n",
      " 34     0.0000040338983837\n",
      " 35     0.0000028358688050\n",
      " 36     0.0000019850337604\n",
      " 37     0.0000013833076865\n",
      " 38     0.0000009797340268\n",
      " 39     0.0000006881530221\n",
      " 40     0.0000004790856873\n",
      " 41     0.0000003307510014\n",
      " 42     0.0000002265332703\n",
      " 43     0.0000001558723758\n",
      " 44     0.0000001121411110\n",
      " 45     0.0000000802289698\n",
      " 46     0.0000000570844786\n",
      " 47     0.0000000404006338\n",
      " 48     0.0000000284453728\n",
      " 49     0.0000000199278900\n",
      " 50     0.0000000138934508\n",
      " 51     0.0000000100763676\n",
      " 52     0.0000000073206685\n",
      "[0.27260107 0.05377343 0.57638731 ... 0.29666009 0.41704149 0.17252501] True\n"
     ]
    }
   ],
   "source": [
    "ans = gauss_seidel_plot_sparse(A,b,x1,omega=1.5)\n",
    "print(ans,np.allclose(ans,x)) #I only ran a few tests, but it seems like omega = 1 frequently results in the fastest convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
