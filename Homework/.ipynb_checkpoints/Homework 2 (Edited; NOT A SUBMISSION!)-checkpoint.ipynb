{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2\n",
    "\n",
    "## by Dion Ho\n",
    "\n",
    "\n",
    "# Import Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from math import pi\n",
    "from math import factorial\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Newton's Method (with $\\frac{|p_n - p_{n-1}|}{|p_n|} \\leq \\epsilon$ stopping criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_method_stop2(x0,f,fp,tol,N):\n",
    "    F = f(x0)\n",
    "    Fp = fp(x0)\n",
    "    iteration = 1\n",
    "    print (\"iter      grad         root:(x,_)           root:(_,y)        interval length\")\n",
    "    print (\"------------------------------------------------------------------------------\")\n",
    "    x = (Fp*x0 - F)/Fp #We run one iteration to get a x1 and (x0-x1) value.\n",
    "    x1 = x0 #x1 is the p_{n-1} value; sorry its a misnomer, I'm lazy to change it.\n",
    "    x0 = x\n",
    "    F = f(x0)\n",
    "    Fp = fp(x0)\n",
    "    print('{:>3d}  {:> 10.5f}  {:> 22.16f}  {:>13.6e}'.format(1, Fp, x, np.abs(F), np.abs(x0-x1)))\n",
    "    iteration = iteration + 1\n",
    "    while (iteration<=N) & (np.abs(x0-x1)>np.abs(tol*x1)):\n",
    "        x = (Fp*x0 - F)/Fp\n",
    "        x1 = x0\n",
    "        x0 = x\n",
    "        F = f(x0)\n",
    "        Fp = fp(x0)\n",
    "        print('{:>3d}  {:> 10.5f}  {:> 22.16f}  {:>13.6e}  {:> 22.16f}'.format(iteration, Fp, x, np.abs(F),np.abs(x0-x1)))\n",
    "        iteration = iteration + 1\n",
    "    if np.abs(x-x0)<=np.abs(tol*x1):\n",
    "        return x0\n",
    "    else:\n",
    "        print(\"Method failed to converge. Try harder!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter      grad         root:(x,_)           root:(_,y)        interval length\n",
      "------------------------------------------------------------------------------\n",
      "  1    -0.74737      0.4266123640724216   5.112309e-02\n",
      "  2    -0.36873      0.4950161565011499   1.312053e-02      0.0684037924287283\n",
      "  3    -0.18314      0.5305988085889202   3.323961e-03      0.0355826520877702\n",
      "  4    -0.09126      0.5487488825747814   8.365522e-04      0.0181500739858612\n",
      "  5    -0.04555      0.5579153030281038   2.098384e-04      0.0091664204533224\n",
      "  6    -0.02276      0.5625215706913647   5.254747e-05      0.0046062676632609\n",
      "  7    -0.01137      0.5648304952776271   1.314787e-05      0.0023089245862624\n",
      "  8    -0.00569      0.5659864085549946   3.288345e-06      0.0011559132773675\n",
      "  9    -0.00284      0.5665647283514305   8.222583e-07      0.0005783197964359\n",
      " 10    -0.00142      0.5668539790905128   2.055861e-07      0.0002892507390824\n",
      " 11    -0.00071      0.5669986271766673   5.139922e-08      0.0001446480861544\n",
      " 12    -0.00036      0.5670709568998106   1.285014e-08      0.0000723297231433\n",
      " 13    -0.00018      0.5671071231813981   3.212577e-09      0.0000361662815875\n",
      " 14    -0.00009      0.5671252066776159   8.031495e-10      0.0000180834962178\n",
      " 15    -0.00004      0.5671342485140862   2.007881e-10      0.0000090418364703\n",
      " 16    -0.00002      0.5671387694550161   5.019707e-11      0.0000045209409298\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5671387694550161"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(a)\n",
    "f = lambda x: x**2 - 2*x*np.exp(-x) + np.exp(-2*x)\n",
    "fp = lambda x: 2*np.exp(-2*x)*(np.exp(x) + 1)*(np.exp(x)*x - 1)\n",
    "newton_method_stop2(0.3,f,fp,1e-5,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter      grad         root:(x,_)           root:(_,y)        interval length\n",
      "------------------------------------------------------------------------------\n",
      "  1     0.00217     -1.1786828328725436   1.279900e-04\n",
      "  2     0.00092     -1.2376200000887663   4.047965e-05      0.0589371672162227\n",
      "  3     0.00039     -1.2817913472216889   1.280496e-05      0.0441713471329226\n",
      "  4     0.00016     -1.3149065788863532   4.051027e-06      0.0331152316646643\n",
      "  5     0.00007     -1.3397374059706373   1.281674e-06      0.0248308270842841\n",
      "  6     0.00003     -1.3583581664428563   4.055124e-07      0.0186207604722191\n",
      "  7     0.00001     -1.3723227415318771   1.283036e-07      0.0139645750890207\n",
      "  8     0.00001     -1.3827957530364929   4.059552e-08      0.0104730115046159\n",
      "  9     0.00000     -1.3906503345627994   1.284458e-08      0.0078545815263065\n",
      " 10     0.00000     -1.3965411959453928   4.064088e-09      0.0058908613825934\n",
      " 11     0.00000     -1.4009593103716593   1.285900e-09      0.0044181144262665\n",
      " 12     0.00000     -1.4042728827302866   4.068661e-10      0.0033135723586273\n",
      " 13     0.00000     -1.4067580559450539   1.287349e-10      0.0024851732147673\n",
      " 14     0.00000     -1.4086219333745069   4.073242e-11      0.0018638774294530\n",
      " 15     0.00000     -1.4100198364844072   1.288791e-11      0.0013979031099003\n",
      " 16     0.00000     -1.4110682536052201   4.077849e-12      0.0010484171208129\n",
      " 17     0.00000     -1.4118545617307952   1.290190e-12      0.0007863081255750\n",
      " 18     0.00000     -1.4124442478610790   4.082290e-13      0.0005896861302839\n",
      " 19     0.00000     -1.4128864695578682   1.291189e-13      0.0004422216967892\n",
      " 20     0.00000     -1.4132179343758560   4.085621e-14      0.0003314648179877\n",
      " 21     0.00000     -1.4134663151760201   1.287859e-14      0.0002483808001641\n",
      " 22     0.00000     -1.4136515092306523   4.107825e-15      0.0001851940546322\n",
      " 23     0.00000     -1.4137903220434502   1.110223e-15      0.0001388128127979\n",
      " 24     0.00000     -1.4138781831526088   4.440892e-16      0.0000878611091586\n",
      " 25     0.00000     -1.4139488170922168   1.110223e-16      0.0000706339396079\n",
      " 26     0.00000     -1.4139847160008898   0.000000e+00      0.0000358989086731\n",
      " 27     0.00000     -1.4139847160008898   0.000000e+00      0.0000000000000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1.4139847160008898"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(b)\n",
    "f = lambda x: np.cos(x + 2**0.5) + x*(x/2 + 2**0.5)\n",
    "fp = lambda x: x - np.sin(x + 2**0.5) + 2**0.5\n",
    "newton_method_stop2(-1.1,f,fp,1e-5,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter      grad         root:(x,_)           root:(_,y)        interval length\n",
      "------------------------------------------------------------------------------\n",
      "  1   1670.46877      3.9281203817224708   9.240626e+01\n",
      "  2   707.45522      3.8728028181894754   2.925066e+01      0.0553175635329954\n",
      "  3   303.10091      3.8314565077979177   9.122787e+00      0.0413463103915577\n",
      "  4   131.11907      3.8013583241816207   2.809005e+00      0.0300981836162970\n",
      "  5    57.15513      3.7799350098217919   8.559359e-01      0.0214233143598288\n",
      "  6    25.05798      3.7649593487547013   2.587117e-01      0.0149756610670906\n",
      "  7    11.03217      3.7546348218974384   7.772826e-02      0.0103245268572629\n",
      "  8     4.87160      3.7475892211112494   2.325202e-02      0.0070456007861890\n",
      "  9     2.15568      3.7428162429994458   6.934561e-03      0.0047729781118035\n",
      " 10     0.95525      3.7395993586017480   2.063773e-03      0.0032168843976979\n",
      " 11     0.42371      3.7374388973757022   6.133084e-04      0.0021604612260457\n",
      " 12     0.18806      3.7359914253673323   1.820839e-04      0.0014474720083699\n",
      " 13     0.08351      3.7350232265386132   5.402294e-05      0.0009681988287191\n",
      " 14     0.03709      3.7343763202789830   1.602108e-05      0.0006469062596302\n",
      " 15     0.01648      3.7339444070597558   4.749832e-06      0.0004319132192272\n",
      " 16     0.00732      3.7336561778350950   1.407956e-06      0.0002882292246609\n",
      " 17     0.00325      3.7334638923629315   4.173198e-07      0.0001922854721634\n",
      " 18     0.00145      3.7333356307488743   1.236913e-07      0.0001282616140572\n",
      " 19     0.00064      3.7332500717343184   3.664172e-08      0.0000855590145559\n",
      " 20     0.00029      3.7331930094692956   1.079752e-08      0.0000570622650229\n",
      " 21     0.00013      3.7331551359148243   3.230525e-09      0.0000378735544713\n",
      " 22     0.00006      3.7331297169957813   9.313226e-10      0.0000254189190430\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.7331297169957813"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(c)\n",
    "f = lambda x: np.exp(3*x) - 27*x**6 + 27*(x**4)*np.exp(x) - 9*(x**2)*np.exp(2*x)\n",
    "fp = lambda x: 3*(np.exp(x) - 6*x)*(np.exp(x) - 3*x**2)**2\n",
    "newton_method_stop2(4,f,fp,1e-5,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If p is a root of $f(x) = 0$ with multiplicity $m$, then\n",
    "$$f(x) = g(x)(h(x) - h(p))^m \\mbox{ where } g(p) \\neq 0.$$\n",
    "\n",
    "This implies that\n",
    "\n",
    "$\\begin{align*}\n",
    "f'(x) &= g'(x)(h(x) - h(p))^m + mg(x)h'(x)(h(x) - h(p))^{m-1} \\\\\n",
    "&= (g'(x)(h(x) - h(p)) - mg(x)(h'(x))(h(x) - h(p)^{m-1}) \\\\\n",
    "&= g_1(x)(h(x) - h(p))^{m-1}.\n",
    "\\end{align*}$\n",
    "\n",
    "Therefore, $f^{(k)}(x) = g_k(x)(h(x) - h(p))^{m-k}$ for $1 \\leq k \\leq m-1$.\n",
    "\n",
    "Therefore, $f(p) = 0, f'(p) = 0, \\ldots, f^{(m-1)}(p) = 0.$\n",
    "\n",
    "According to Burden and Faires, quadratic convergence might not occur if $f(p) = 0$ and $f'(p) = 0$.\n",
    "\n",
    "If we let $g(x) = x - \\phi(x)f(x)$, then $g'(x) = 1 - \\phi'(x)f(x) -  \\phi(x)f'(x)$. However, if $f'(p) = 0$, then $g'(x) = 1$ for all function $\\phi$. $g'(x) \\neq 0$ implies linear convergence of any fixed point iteration scheme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Newton's method with multiplicity of root correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_method_stop2_mulcorrection(x0,f,fp,fpp,tol,N):\n",
    "    F = f(x0)\n",
    "    Fp = fp(x0)\n",
    "    Fpp = fpp(x0)\n",
    "    iteration = 1\n",
    "    print (\"iter      divisor         root:(x,_)           root:(_,y)        interval length\")\n",
    "    print (\"------------------------------------------------------------------------------\")\n",
    "    x = x0 - Fp*F/(Fp**2 - F*Fpp) #We run one iteration to get a x1 and (x0-x1) value.\n",
    "    x1 = x0 #x1 is the p_{n-1} value; sorry its a misnomer, I'm lazy to change it.\n",
    "    x0 = x\n",
    "    F = f(x0)\n",
    "    Fp = fp(x0)\n",
    "    Fpp = fpp(x0)\n",
    "    print('{:>3d}  {:> 10.5f}  {:> 22.16f}  {:>13.6e}'.format(1, Fp, x, np.abs(F), np.abs(x0-x1)))\n",
    "    iteration = iteration + 1\n",
    "    while (iteration<=N) & (np.abs(x0-x1)>np.abs(tol*x1)):\n",
    "        x = x0 - Fp*F/(Fp**2 - F*Fpp)\n",
    "        x1 = x0\n",
    "        x0 = x\n",
    "        F = f(x0)\n",
    "        Fp = fp(x0)\n",
    "        Fpp = fpp(x0)\n",
    "        print('{:>3d}  {:> 10.5f}  {:> 22.16f}  {:>13.6e}  {:> 22.16f}'.format(iteration, (Fp**2 - F*Fpp), x, np.abs(F),np.abs(x0-x1)))\n",
    "        iteration = iteration + 1\n",
    "    if np.abs(x-x0)<=np.abs(tol*x1):\n",
    "        return x0\n",
    "    else:\n",
    "        print(\"Method failed to converge. Try harder!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Bisection Method but with results stored in an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bisection_method_withresults(a,b,f,tol,N):\n",
    "    FA,FB = f(a), f(b)\n",
    "    results=[]\n",
    "    iteration = 1\n",
    "    if FA*FB<0:\n",
    "        print (\"iter      a           b            root:(x,_)           root:(_,y)\")\n",
    "        print (\"------------------------------------------------------------------\")\n",
    "        p = (a + b)/2\n",
    "        FP = f(p)\n",
    "        while (np.abs((b-a)/2)>tol) & (iteration <= N):\n",
    "            if FA*FP<0:\n",
    "                b=p\n",
    "                FB=FP\n",
    "            else:\n",
    "                a=p\n",
    "                FA=FP\n",
    "            p = (a+b)/2\n",
    "            FP = f(p)\n",
    "            print('{:>3d}  {:> 10.5f}  {:> 10.5f}  {:> 22.16f}  {:>13.6e}'.format(iteration, a, b, p, abs(FP)))\n",
    "            results.append(p)\n",
    "            iteration = iteration + 1\n",
    "        if np.abs((b-a)/2)>tol:\n",
    "            print(\"Method failed to converge\")\n",
    "        else:\n",
    "            return p, results\n",
    "    else:\n",
    "             print(\"Cannot ensure existence of root\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter      divisor         root:(x,_)           root:(_,y)        interval length\n",
      "------------------------------------------------------------------------------\n",
      "  1     0.08112      0.5838083972615007   6.779926e-04\n",
      "  2     0.00000      0.5671927362614900   6.004397e-09      0.0166156610000107\n",
      "  3     0.00000      0.5671432908508617   5.551115e-17      0.0000494454106283\n",
      "  4    -0.00000      0.5671432912844749   5.551115e-17      0.0000000004336133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5671432912844749"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(a)\n",
    "f = lambda x: x**2 - 2*x*np.exp(-x) + np.exp(-2*x)\n",
    "fp = lambda x: 2*np.exp(-2*x)*(np.exp(x) + 1)*(np.exp(x)*x - 1)\n",
    "fpp = lambda x: -2*np.exp(-x)*(x-2) + 4*np.exp(-2*x) + 2\n",
    "newton_method_stop2_mulcorrection(0.3,f,fp,fpp,1e-5,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter      divisor         root:(x,_)           root:(_,y)        interval length\n",
      "------------------------------------------------------------------------------\n",
      "  1     0.00000     -1.4131816691807593   4.718448e-14\n",
      "  2     0.00000     -1.4142085583550834   1.110223e-16      0.0010268891743241\n",
      "  3     0.00000     -1.4142085583550834   1.110223e-16      0.0000000000000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1.4142085583550834"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(b)\n",
    "f = lambda x: np.cos(x + 2**0.5) + x*(x/2 + 2**0.5)\n",
    "fp = lambda x: x - np.sin(x + 2**0.5) + 2**0.5\n",
    "fpp = lambda x: 1 - np.cos(x + 2**0.5)\n",
    "newton_method_stop2_mulcorrection(-1.1,f,fp,fpp,1e-5,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter      divisor         root:(x,_)           root:(_,y)        interval length\n",
      "------------------------------------------------------------------------------\n",
      "  1    65.06103      3.6720356968913230   1.403597e+00\n",
      "  2     0.02357      3.7295805255521182   3.100712e-04      0.0575448286607951\n",
      "  3     0.00000      3.7330677255408902   2.910383e-11      0.0034871999887720\n",
      "  4    -0.00000      3.7330640655685072   5.820766e-11      0.0000036599723829\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.7330640655685072"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(c)\n",
    "f = lambda x: np.exp(3*x) - 27*x**6 + 27*(x**4)*np.exp(x) - 9*(x**2)*np.exp(2*x)\n",
    "fp = lambda x: 3*(np.exp(x) - 6*x)*(np.exp(x) - 3*x**2)**2\n",
    "fpp = lambda x: 6*(np.exp(x) - 3*x**2)*(np.exp(x) - 6*x)**2 + 3*(np.exp(x) - 6)*(np.exp(x) - 3*x**2)**2\n",
    "newton_method_stop2_mulcorrection(4,f,fp,fpp,1e-5,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all three functions in Q1, Newton's Method with multiplicity of root correction results in faster convergence. In fact, for 1(c) and especially 1(b), the convergence appears to be faster than quadratic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the sequence $\\displaystyle\\left(p_{n+1} = p_n^3 \\mbox{ with } p_0 = 0.5\\right)_{n \\in \\mathbb{N}^0},$ i.e. $\\displaystyle\\left(2^{-3^n}\\right)_{n \\in \\mathbb{N}^0}$. This sequence converges to $0$.\n",
    "\n",
    "Let $\\alpha = 3$ in $\\displaystyle\\lim_{n\\rightarrow\\infty}\\frac{\\mid p_{n+1} - p \\mid}{\\mid p_{n} - p \\mid^\\alpha} = \\lambda$. $\\displaystyle\\lim_{n\\rightarrow\\infty}\\frac{\\mid p_{n+1}\\mid}{\\mid p_{n}\\mid^3} = \\lambda \\implies \\lim_{n\\rightarrow\\infty}\\frac{\\mid p_{n}\\mid^3}{\\mid p_{n}\\mid^3} = \\lambda \\implies \\lambda = 1$. \n",
    "Therefore, the sequence converges to $0$ with order $3$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error of the bisection algorithm is the length of the interval which is given by the sequence $\\displaystyle\\left(p_{n+1} = 0.5p_n \\mbox{ with } p_0 = \\mbox{some } \\mathbb{R}^+\\right)$, i.e. $\\displaystyle\\left(\\frac{a}{2^n} \\mbox{ for some } a\\in\\mathbb{R}^+\\right)_{n \\in \\mathbb{N}^0}$. This sequence converges to $0$.\n",
    "\n",
    "Let $\\alpha = 1$ in $\\displaystyle\\lim_{n\\rightarrow\\infty}\\frac{\\mid p_{n+1} - p \\mid}{\\mid p_{n} - p \\mid^\\alpha} = \\lambda$. $\\displaystyle\\lim_{n\\rightarrow\\infty}\\frac{\\mid p_{n+1}\\mid}{\\mid p_{n}\\mid} = \\lambda \\implies \\lim_{n\\rightarrow\\infty}\\frac{\\mid 0.5p_{n}\\mid}{\\mid p_{n}\\mid} = \\lambda \\implies \\lambda = 0.5$. \n",
    "Therefore, the sequence converges linearly to $0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter      a           b            root:(x,_)           root:(_,y)\n",
      "------------------------------------------------------------------\n",
      "  1     3.00000     4.00000      3.5000000000000000   4.801216e+01\n",
      "  2     3.50000     4.00000      3.7500000000000000   3.711999e-02\n",
      "  3     3.50000     3.75000      3.6250000000000000   6.828201e+00\n",
      "  4     3.62500     3.75000      3.6875000000000000   6.100351e-01\n",
      "  5     3.68750     3.75000      3.7187500000000000   2.067434e-02\n",
      "  6     3.71875     3.75000      3.7343750000000000   1.597218e-05\n",
      "  7     3.71875     3.73438      3.7265625000000000   1.987165e-03\n",
      "  8     3.72656     3.73438      3.7304687500000000   1.291051e-04\n",
      "  9     3.73047     3.73438      3.7324218750000000   2.071203e-06\n",
      " 10     3.73242     3.73438      3.7333984375000000   2.384768e-07\n",
      " 11     3.73242     3.73340      3.7329101562500000   3.518653e-08\n",
      " 12     3.73291     3.73340      3.7331542968750000   3.085006e-09\n",
      " 13     3.73291     3.73315      3.7330322265625000   7.566996e-10\n",
      " 14     3.73303     3.73315      3.7330932617187500   0.000000e+00\n",
      " 15     3.73309     3.73315      3.7331237792968750   6.693881e-10\n",
      " 16     3.73312     3.73315      3.7331390380859375   1.600711e-09\n",
      " 17     3.73314     3.73315      3.7331466674804688   2.270099e-09\n",
      " 18     3.73315     3.73315      3.7331504821777344   2.706656e-09\n",
      " 19     3.73315     3.73315      3.7331523895263672   2.881279e-09\n",
      " 20     3.73315     3.73315      3.7331533432006836   3.026798e-09\n",
      " 21     3.73315     3.73315      3.7331538200378418   3.055902e-09\n",
      " 22     3.73315     3.73315      3.7331540584564209   3.172318e-09\n",
      " 23     3.73315     3.73315      3.7331541776657104   3.143214e-09\n",
      " 24     3.73315     3.73315      3.7331542372703552   3.085006e-09\n",
      " 25     3.73315     3.73315      3.7331542670726776   3.143214e-09\n",
      " 26     3.73315     3.73315      3.7331542819738388   3.114110e-09\n",
      " 27     3.73315     3.73315      3.7331542894244194   3.143214e-09\n",
      " 28     3.73315     3.73315      3.7331542931497097   3.114110e-09\n",
      " 29     3.73315     3.73315      3.7331542950123549   3.085006e-09\n",
      " 30     3.73315     3.73315      3.7331542959436774   3.085006e-09\n",
      " 31     3.73315     3.73315      3.7331542964093387   3.114110e-09\n",
      " 32     3.73315     3.73315      3.7331542966421694   3.085006e-09\n",
      " 33     3.73315     3.73315      3.7331542967585847   3.143214e-09\n",
      " 34     3.73315     3.73315      3.7331542968167923   3.114110e-09\n",
      " 35     3.73315     3.73315      3.7331542968458962   3.114110e-09\n",
      " 36     3.73315     3.73315      3.7331542968604481   3.114110e-09\n",
      " 37     3.73315     3.73315      3.7331542968677240   3.143214e-09\n",
      " 38     3.73315     3.73315      3.7331542968713620   3.085006e-09\n",
      " 39     3.73315     3.73315      3.7331542968731810   3.172318e-09\n",
      " 40     3.73315     3.73315      3.7331542968740905   3.143214e-09\n",
      " 41     3.73315     3.73315      3.7331542968745453   3.055902e-09\n",
      " 42     3.73315     3.73315      3.7331542968747726   3.143214e-09\n",
      " 43     3.73315     3.73315      3.7331542968748863   3.172318e-09\n",
      " 44     3.73315     3.73315      3.7331542968749432   3.172318e-09\n",
      " 45     3.73315     3.73315      3.7331542968749716   3.085006e-09\n",
      " 46     3.73315     3.73315      3.7331542968749858   3.143214e-09\n",
      " 47     3.73315     3.73315      3.7331542968749929   3.143214e-09\n",
      " 48     3.73315     3.73315      3.7331542968749964   3.085006e-09\n",
      " 49     3.73315     3.73315      3.7331542968749982   3.143214e-09\n",
      " 50     3.73315     3.73315      3.7331542968749991   3.085006e-09\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.grid(b=None, which='major', axis='both', **kwargs)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = lambda x: np.exp(3*x) - 27*x**6 + 27*(x**4)*np.exp(x) - 9*(x**2)*np.exp(2*x)\n",
    "p, results = bisection_method_withresults(3,5,f,1e-15,100)\n",
    "plot=[[],[]]\n",
    "for i in range(0, len(results)-1):\n",
    "    plot[0].append(np.abs(results[i]-p))\n",
    "    plot[1].append(np.abs(results[i+1]-p))\n",
    "plt.loglog(plot[0],plot[1], '.') #Apart from a few anomalous plots, the convergence is linear.\n",
    "plt.grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose sequence $(p_n)$ converges to $p$ of order $\\alpha$ and $n$ is large. Therefore, $\\displaystyle\\frac{| p_{n+1} - p|}{| p_n - p|^\\alpha} \\approx \\lambda \\implies \\frac{| p_n - p|}{| p_{n-1} - p|^\\alpha} \\approx \\lambda$. \n",
    "\n",
    "$\\displaystyle\\frac{| p_n - p|}{| p_{n-1} - p|^\\alpha} \\approx \\lambda \\implies \\left(\\frac{1}{\\lambda}| p_n - p|\\right)^{1/\\alpha} \\approx | p_{n-1} - p|$.\n",
    "\n",
    "Given $| p_{n+1} - p| \\approx C | p_n - p|| p_{n-1} - p|$, we have $\\displaystyle| p_{n+1} - p| \\approx C\\left(\\frac{1}{\\lambda}\\right)^{1/\\alpha}|p_n - p|^{1/\\alpha}|p_n - p| \\implies \\frac{| p_{n+1} - p|}{| p_n - p|^{1+1/\\alpha}} \\approx C\\left(\\frac{1}{\\lambda}\\right)^{1/\\alpha}$.\n",
    "\n",
    "Since $\\displaystyle C\\left(\\frac{1}{\\lambda}\\right)^{1/\\alpha}$ is a positive constant, $\\displaystyle\\frac{1+\\alpha}{\\alpha} = \\alpha \\implies \\alpha^2 - \\alpha - 1 = 0 \\implies \\alpha = \\frac{1 + \\sqrt{5}}{2} \\approx 1.618$ since $\\alpha > 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accelerating Convergence: Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Newton's Method (with $|p_n - p_{n-1}| \\leq \\epsilon$ stopping criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_method_stop1(x0,f,fp,tol,N):\n",
    "    F = f(x0)\n",
    "    Fp = fp(x0)\n",
    "    results=[]\n",
    "    iteration = 1\n",
    "    print (\"iter      grad         root:(x,_)           root:(_,y)        interval length\")\n",
    "    print (\"------------------------------------------------------------------------------\")\n",
    "    x = (Fp*x0 - F)/Fp #We run one iteration to get a (x0-x1) value, though if we immediately get the root, we will just return it.\n",
    "    results.append(x)\n",
    "    x1 = x0 #x1 is the p_{n-1} value; sorry its a misnomer, I'm lazy to change it.\n",
    "    x0 = x\n",
    "    F = f(x0)\n",
    "    Fp = fp(x0)\n",
    "    print('{:>3d}  {:> 10.5f}  {:> 22.16f}  {:>13.6e}  {:> 22.16f}'.format(1, Fp, x, np.abs(F),np.abs(x0-x1)))\n",
    "    if np.abs(F)<=tol:\n",
    "        return x0\n",
    "    else:\n",
    "        iteration = iteration + 1\n",
    "        while (iteration<=N) & (np.abs(x0-x1)>tol):\n",
    "            x = (Fp*x0 - F)/Fp\n",
    "            results.append(x)\n",
    "            x1 = x0\n",
    "            x0 = x\n",
    "            F = f(x0)\n",
    "            Fp = fp(x0)\n",
    "            print('{:>3d}  {:> 10.5f}  {:> 22.16f}  {:>13.6e}  {:> 22.16f}'.format(iteration, Fp, x, np.abs(F),np.abs(x0-x1)))\n",
    "            iteration = iteration + 1\n",
    "        if np.abs(x-x0)<=tol:\n",
    "            return x0, results\n",
    "        else:\n",
    "            print(\"Method failed to converge. Try harder!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter      grad         root:(x,_)           root:(_,y)        interval length\n",
      "------------------------------------------------------------------------------\n",
      "  1     0.23802     -0.0511421365733425   9.211568e-03      0.0511421365733425\n",
      "  2     0.10164     -0.0898424758150268   2.886715e-03      0.0387003392416843\n",
      "  3     0.04388     -0.1182447360258248   8.915830e-04      0.0284022602107980\n",
      "  4     0.01910     -0.1385655958400078   2.721970e-04      0.0203208598141830\n",
      "  5     0.00837     -0.1528161929692974   8.237076e-05      0.0142505971292896\n",
      "  6     0.00368     -0.1626602525902589   2.476594e-05      0.0098440596209615\n",
      "  7     0.00163     -0.1693861756223201   7.412004e-06      0.0067259230320612\n",
      "  8     0.00072     -0.1739460644747723   2.211159e-06      0.0045598888524522\n",
      "  9     0.00032     -0.1770208137708657   6.581784e-07      0.0030747492960934\n",
      " 10     0.00014     -0.1790864552280062   1.956199e-07      0.0020656414571405\n",
      " 11     0.00006     -0.1804706766816483   5.808176e-08      0.0013842214536422\n",
      " 12     0.00003     -0.1813966891506640   1.723331e-08      0.0009260124690156\n",
      " 13     0.00001     -0.1820154613767330   5.110905e-09      0.0006187722260690\n",
      " 14     0.00001     -0.1824286147391486   1.515281e-09      0.0004131533624157\n",
      " 15     0.00000     -0.1827043349434589   4.491577e-10      0.0002757202043102\n",
      " 16     0.00000     -0.1828882751315548   1.331205e-10      0.0001839401880959\n"
     ]
    }
   ],
   "source": [
    "f = lambda x: np.exp(6*x) + 3*(np.log(2)**2)*np.exp(2*x) - np.log(8)*np.exp(4*x) - np.log(2)**3\n",
    "fp = lambda x: 6*np.exp(6*x) + 6*(np.log(2)**2)*np.exp(2*x) - 4*np.log(8)*np.exp(4*x)\n",
    "newton_method_stop1(0,f,fp,0.0002,100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aitken's Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter      grad         root:(x,_)           root:(_,y)        interval length\n",
      "------------------------------------------------------------------------------\n",
      "  1     0.23802     -0.0511421365733425   9.211568e-03      0.0511421365733425\n",
      "  2     0.10164     -0.0898424758150268   2.886715e-03      0.0387003392416843\n",
      "  3     0.04388     -0.1182447360258248   8.915830e-04      0.0284022602107980\n",
      "  4     0.01910     -0.1385655958400078   2.721970e-04      0.0203208598141830\n",
      "  5     0.00837     -0.1528161929692974   8.237076e-05      0.0142505971292896\n",
      "  6     0.00368     -0.1626602525902589   2.476594e-05      0.0098440596209615\n",
      "  7     0.00163     -0.1693861756223201   7.412004e-06      0.0067259230320612\n",
      "  8     0.00072     -0.1739460644747723   2.211159e-06      0.0045598888524522\n",
      "  9     0.00032     -0.1770208137708657   6.581784e-07      0.0030747492960934\n",
      " 10     0.00014     -0.1790864552280062   1.956199e-07      0.0020656414571405\n",
      " 11     0.00006     -0.1804706766816483   5.808176e-08      0.0013842214536422\n",
      " 12     0.00003     -0.1813966891506640   1.723331e-08      0.0009260124690156\n",
      " 13     0.00001     -0.1820154613767330   5.110905e-09      0.0006187722260690\n",
      " 14     0.00001     -0.1824286147391486   1.515281e-09      0.0004131533624157\n",
      " 15     0.00000     -0.1827043349434589   4.491577e-10      0.0002757202043102\n",
      " 16     0.00000     -0.1828882751315548   1.331205e-10      0.0001839401880959\n",
      "\n",
      "  0      -0.051142136573342        -0.064445431703108\n",
      "  1      -0.089842475815027        -0.094138710877246\n",
      "  2      -0.118244736025825        -0.119947151078497\n",
      "  3      -0.138565595840008        -0.139286918410616\n",
      "  4      -0.152816192969297        -0.153130056437536\n",
      "  5      -0.162660252590259        -0.162798389689639\n",
      "  6      -0.169386175622320        -0.169447284009083\n",
      "  7      -0.173946064474772        -0.173973161206561\n",
      "  8      -0.177020813770866        -0.177032842520221\n",
      "  9      -0.179086455228006        -0.179091797957426\n",
      " 10      -0.180470676681648        -0.180473050390800\n",
      " 11      -0.181396689150664        -0.181397743916850\n",
      " 12      -0.182015461376733        -0.182015930104172\n",
      " 13      -0.182428614739149        -0.182428823046690\n"
     ]
    }
   ],
   "source": [
    "f = lambda x: np.exp(6*x) + 3*(np.log(2)**2)*np.exp(2*x) - np.log(8)*np.exp(4*x) - np.log(2)**3\n",
    "fp = lambda x: 6*np.exp(6*x) + 6*(np.log(2)**2)*np.exp(2*x) - 4*np.log(8)*np.exp(4*x)\n",
    "p, results = newton_method_stop1(0,f,fp,0.0002,100)\n",
    "results_Atkin=np.zeros(len(results))\n",
    "print(\"\")\n",
    "for n in range(1,len(results)):\n",
    "    if n>=2:\n",
    "        results_Atkin[n-2] = results[n-2] - (results[n-1]-results[n-2])**2/(results[n]-2*results[n-1]-results[n-2])\n",
    "        print(\"%3d      % 3.15f        % 3.15f\" %(n-2,results[n-2],results_Atkin[n-2])) #There is almost no improvement in convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolation: Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Lagrange Polynomial Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L(xvals,kk,x):\n",
    "    value = np.ones(x.size)\n",
    "    n = xvals.size\n",
    "    for ii in range(0,n):\n",
    "        if ii != kk:\n",
    "            value *= (x-xvals[ii])/(xvals[kk]-xvals[ii])\n",
    "    return value\n",
    "    \n",
    "def p_Lagrange(xvals,yvals,x):\n",
    "    n = yvals.size\n",
    "    pLagrange = np.zeros(x.size)\n",
    "    for kk in range(0,n):\n",
    "        pLagrange += yvals[kk]*L(xvals,kk,x)\n",
    "    return pLagrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate = 0.898; Absolute Error = 2.347e-03\n"
     ]
    }
   ],
   "source": [
    "# 1(a)\n",
    "f = lambda x: np.cos(x)\n",
    "xvals = np.array([0, .6, .9])\n",
    "x = np.array([0.45])\n",
    "yvals = f(xvals)\n",
    "estimate = p_Lagrange(xvals,yvals,x)[0] #Estimate\n",
    "abs_error = np.abs(estimate - f(x[0])) #\n",
    "print('Estimate = {:<1.3f}; Absolute Error = {:<1.3e}'.format(estimate,abs_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate = 1.203; Absolute Error = 7.357e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.26491106, 1.37840488])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1(b)\n",
    "f = lambda x: np.sqrt(1+x)\n",
    "xvals = np.array([0, .6, .9])\n",
    "x = np.array([0.45])\n",
    "yvals = f(xvals)\n",
    "estimate = p_Lagrange(xvals,yvals,x)[0] #Estimate\n",
    "abs_error = np.abs(estimate - f(x[0])) #\n",
    "print('Estimate = {:<1.3f}; Absolute Error = {:<1.3e}'.format(estimate,abs_error))\n",
    "yvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate = 0.368; Absolute Error = 3.273e-03\n"
     ]
    }
   ],
   "source": [
    "# 1(c)\n",
    "f = lambda x: np.log(np.abs(1+x))\n",
    "xvals = np.array([0, .6, .9])\n",
    "x = np.array([0.45])\n",
    "yvals = f(xvals)\n",
    "estimate = p_Lagrange(xvals,yvals,x)[0] #Estimate\n",
    "abs_error = np.abs(estimate - f(x[0])) #\n",
    "print('Estimate = {:<1.3f}; Absolute Error = {:<1.3e}'.format(estimate,abs_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate = 0.455; Absolute Error = 2.844e-02\n"
     ]
    }
   ],
   "source": [
    "# 1(d)\n",
    "f = lambda x: np.tan(x)\n",
    "xvals = np.array([0, .6, .9])\n",
    "x = np.array([0.45])\n",
    "yvals = f(xvals)\n",
    "estimate = p_Lagrange(xvals,yvals,x)[0] #Estimate\n",
    "abs_error = np.abs(estimate - f(x[0])) #\n",
    "print('Estimate = {:<1.3f}; Absolute Error = {:<1.3e}'.format(estimate,abs_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\displaystyle P'_n(x) = \\sum_{k=0}^n f(x_k)L'_{n,k}(x)$ since $f(x_k)$ is just a constant. We want to find a formula for $L'_{n,k}(x)$.\n",
    "\n",
    "$\\displaystyle\\ln(L_{n,k}(x)) = \\sum_{j=0,j\\neq k}^n \\ln\\frac{x - x_j}{x_k - x_j} \\implies \\frac{d}{dx}\\ln(L_{n,k}(x)) = \\frac{L'_{n,k}(x)}{L_{n,k}(x)} = \\sum_{j=0,j\\neq k}^n \\frac{1}{x_k - x_j}\\frac{x_k - x_j}{x - x_j} = \\sum_{j=0,j\\neq k}^n \\frac{1}{x - x_j}$.\n",
    "\n",
    "Therefore, $\\displaystyle L'_{n,k}(x) = L_{n,k}(x)\\left(\\sum_{j=0,j\\neq k}^n \\frac{1}{x - x_j}\\right)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L(xvals,kk,x):\n",
    "    value = np.ones(x.size)\n",
    "    n = xvals.size\n",
    "    for ii in range(0,n):\n",
    "        if ii != kk:\n",
    "            value *= (x-xvals[ii])/(xvals[kk]-xvals[ii])\n",
    "    return value\n",
    "\n",
    "def LpSum(xvals,kk,x):\n",
    "    lval = np.zeros(x.size)\n",
    "    n = xvals.size\n",
    "    for ii in range(0,n):\n",
    "        if ii != kk:\n",
    "            lval += 1/(x-xvals[ii])\n",
    "    return lval\n",
    "\n",
    "def p_LagrangeP(xvals,fvals,x):\n",
    "    n = fvals.size\n",
    "    pLagrange = np.zeros(x.size)\n",
    "    for kk in range(0,n):\n",
    "        pLagrange += fvals[kk]*L(xvals,kk,x)*LpSum(xvals,kk,x)\n",
    "    return pLagrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate = -0.420; Absolute Error = 1.453e-02\n"
     ]
    }
   ],
   "source": [
    "# 2(a)\n",
    "f = lambda x: np.cos(x)\n",
    "fp = lambda x: -np.sin(x)\n",
    "xvals = np.array([0, .6, .9])\n",
    "x = np.array([0.45])\n",
    "yvals = f(xvals)\n",
    "estimate = p_LagrangeP(xvals,yvals,x)[0] #Estimate\n",
    "abs_error = np.abs(estimate - fp(x[0])) #\n",
    "print('Estimate = {:<1.3f}; Absolute Error = {:<1.3e}'.format(estimate,abs_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate = 0.420; Absolute Error = 5.222e-03\n"
     ]
    }
   ],
   "source": [
    "# 2(b)\n",
    "f = lambda x: np.sqrt(1+x)\n",
    "fp = lambda x: 0.5*np.sqrt(1/(1+x))\n",
    "xvals = np.array([0, .6, .9])\n",
    "x = np.array([0.45])\n",
    "yvals = f(xvals)\n",
    "estimate = p_LagrangeP(xvals,yvals,x)[0] #Estimate\n",
    "abs_error = np.abs(estimate - fp(x[0])) #\n",
    "print('Estimate = {:<1.3f}; Absolute Error = {:<1.3e}'.format(estimate,abs_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate = 0.713; Absolute Error = 2.352e-02\n"
     ]
    }
   ],
   "source": [
    "# 2(c)\n",
    "f = lambda x: np.log(np.abs(1+x))\n",
    "fp = lambda x: 1/(1+x)\n",
    "xvals = np.array([0, .6, .9])\n",
    "x = np.array([0.45])\n",
    "yvals = f(xvals)\n",
    "estimate = p_LagrangeP(xvals,yvals,x)[0] #Estimate\n",
    "abs_error = np.abs(estimate - fp(x[0])) #\n",
    "print('Estimate = {:<1.3f}; Absolute Error = {:<1.3e}'.format(estimate,abs_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate = 1.400; Absolute Error = 1.668e-01\n"
     ]
    }
   ],
   "source": [
    "# 2(d)\n",
    "f = lambda x: np.tan(x)\n",
    "fp = lambda x: 1/(np.cos(x)**2)\n",
    "xvals = np.array([0, .6, .9])\n",
    "x = np.array([0.45])\n",
    "yvals = f(xvals)\n",
    "estimate = p_LagrangeP(xvals,yvals,x)[0] #Estimate\n",
    "abs_error = np.abs(estimate - fp(x[0])) #\n",
    "print('Estimate = {:<1.3f}; Absolute Error = {:<1.3e}'.format(estimate,abs_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for Cubic Spline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cubic_spline_coeffs(xvals,yvals):\n",
    "\n",
    "    n = xvals.size - 1\n",
    "    h = xvals[1:]-xvals[0:-1]\n",
    "\n",
    "    d0 = np.hstack([1,2*(h[0:-1]+h[1:]),1])\n",
    "    d1 = np.hstack([0,h[1:]])\n",
    "    dm1 = np.hstack([h[0:-1],0])\n",
    "    # create the \"A\" matrix by using the np.diag command\n",
    "    A = np.diag(d0) + np.diag(d1,1)+ np.diag(dm1,-1)\n",
    "\n",
    "    \n",
    "    # create the right-hand-side of A*x = b\n",
    "    # recall that a_j = y_j\n",
    "    aVec = yvals\n",
    "    rhs = np.hstack([0,(3./h[1:])*(aVec[2:]-aVec[1:-1])-(3/h[0:-1])*(aVec[1:-1]-aVec[0:-2]),0])\n",
    "    \n",
    "    # use the linalg.solve command to solve Ax = b  \n",
    "    cVec = np.linalg.solve(A,rhs)\n",
    "\n",
    "    \n",
    "    # use the remaining formula to determine d_j and b_j\n",
    "    dVec = (cVec[1:]-cVec[0:-1])/(3*h)\n",
    "    bVec = 1/h*(aVec[1:] - aVec[0:-1]) - h/3*(2*cVec[0:-1]+cVec[1:])\n",
    "    \n",
    "    # stack all of the coefficients into a matrix so that the coefficients are in the form \n",
    "    #            a_0, a_1, ...\n",
    "    #            b_0, b_1, ...\n",
    "    #            c_0, c_1, ...\n",
    "    #            d_0, d_1, ...\n",
    "    \n",
    "    SCoeffs = np.vstack([aVec[0:n], bVec[0:n], cVec[0:n], dVec[0:n]])\n",
    "    return SCoeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cubic_spline_f(x, coeffs, yvals):\n",
    "    n = len(coeffs[0])\n",
    "    ans = 0\n",
    "    for ii in range(0,3):\n",
    "        for jj in range(0,n):\n",
    "            ans += coeffs[ii][jj]*(x**ii)*((yvals[jj]<x) and (x<=yvals[jj+1]))\n",
    "    return ans\n",
    "\n",
    "def cubic_spline_fp(x, coeffs, yvals):\n",
    "    n = len(coeffs[0])\n",
    "    ans = 0\n",
    "    for ii in range(1,3):\n",
    "        for jj in range(0,n):\n",
    "            ans += coeffs[ii][jj]*ii*(x**(ii-1))*((yvals[jj]<x) and (x<=yvals[jj+1]))\n",
    "    return ans\n",
    "\n",
    "def cubic_spline_fpp(x, coeffs, yvals):\n",
    "    n = len(coeffs[0])\n",
    "    ans = 0\n",
    "    for ii in range(2,3):\n",
    "        for jj in range(0,n):\n",
    "            ans += coeffs[ii][jj]*ii*(ii-1)*(x**(ii-2))*((yvals[jj]<x) and (x<=yvals[jj+1]))\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrating the spline over $[0,1]$ produces $-0.218$ whereas the actual value is $0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f value comparison of spline vs actual\n",
      "6.123233995736766e-17\n",
      "0.0\n",
      "6.123233995736766e-17\n",
      "\n",
      "\n",
      "fp value comparison of spline vs actual\n",
      "0.0\n",
      "-3.141592653589793\n",
      "3.141592653589793\n",
      "\n",
      "\n",
      "fpp value comparison of spline vs actual\n",
      "-0.6974391799569624\n",
      "-6.043389719322356e-16\n",
      "6.043389719322356e-16\n"
     ]
    }
   ],
   "source": [
    "fp_actual = lambda x: -pi*np.sin(pi*x)\n",
    "fpp_actual = lambda x: -(pi**2)*np.cos(pi*x)\n",
    "\n",
    "f_actual = lambda x: np.cos(np.pi*x)\n",
    "xvals = np.array([0,0.25,0.5,0.75,1])\n",
    "yvals = f_actual(xvals)\n",
    "coeffs = np.array([[1,0.793,0.793,6.382],\n",
    "                   [-0.758,1.726,1.726,-20.63],\n",
    "                   [0,-9.936,-9.936,19.872],\n",
    "                   [-6.6240,6.6240,6.6240,-6.6240]])\n",
    "\n",
    "print(\"f value comparison of spline vs actual\")\n",
    "print(f_actual(0.5))\n",
    "print(cubic_spline_f(0.5,coeffs,yvals))\n",
    "print(np.abs(cubic_spline_f(0.5,coeffs,yvals) - f_actual(0.5)))\n",
    "print()\n",
    "print()\n",
    "print(\"fp value comparison of spline vs actual\")\n",
    "print(cubic_spline_fp(0.5,coeffs,yvals))\n",
    "print(fp_actual(0.5))\n",
    "print(np.abs(cubic_spline_fp(0.5,coeffs,yvals) - fp_actual(0.5)))\n",
    "print()\n",
    "print()\n",
    "print(\"fpp value comparison of spline vs actual\")\n",
    "print(fpp(0.5))\n",
    "print(fpp_actual(0.5))\n",
    "print(np.abs(cubic_spline_fpp(0.5,coeffs, yvals) - fpp_actual(0.5)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
