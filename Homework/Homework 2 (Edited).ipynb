{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2\n",
    "\n",
    "## by Dion Ho\n",
    "\n",
    "\n",
    "# Import Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from math import pi\n",
    "from math import factorial\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Newton's Method (with $\\frac{|p_n - p_{n-1}|}{|p_n|} \\leq \\epsilon$ stopping criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_method_stop2(x0,f,fp,tol,N):\n",
    "    F = f(x0)\n",
    "    Fp = fp(x0)\n",
    "    iteration = 1\n",
    "    print (\"iter      grad         root:(x,_)           root:(_,y)        interval length\")\n",
    "    print (\"------------------------------------------------------------------------------\")\n",
    "    x = (Fp*x0 - F)/Fp #We run one iteration to get a x1 and (x0-x1) value.\n",
    "    x1 = x0 #x1 is the p_{n-1} value; sorry its a misnomer, I'm lazy to change it.\n",
    "    x0 = x\n",
    "    F = f(x0)\n",
    "    Fp = fp(x0)\n",
    "    print('{:>3d}  {:> 10.5f}  {:> 22.16f}  {:>13.6e}'.format(1, Fp, x, np.abs(F), np.abs(x0-x1)))\n",
    "    iteration = iteration + 1\n",
    "    while (iteration<=N) & (np.abs(x0-x1)>np.abs(tol*x1)):\n",
    "        x = (Fp*x0 - F)/Fp\n",
    "        x1 = x0\n",
    "        x0 = x\n",
    "        F = f(x0)\n",
    "        Fp = fp(x0)\n",
    "        print('{:>3d}  {:> 10.5f}  {:> 22.16f}  {:>13.6e}  {:> 22.16f}'.format(iteration, Fp, x, np.abs(F),np.abs(x0-x1)))\n",
    "        iteration = iteration + 1\n",
    "    if np.abs(x-x0)<=np.abs(tol*x1):\n",
    "        return x0\n",
    "    else:\n",
    "        print(\"Method failed to converge. Try harder!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter      grad         root:(x,_)           root:(_,y)        interval length\n",
      "------------------------------------------------------------------------------\n",
      "  1    -0.74737      0.4266123640724216   5.112309e-02\n",
      "  2    -0.36873      0.4950161565011499   1.312053e-02      0.0684037924287283\n",
      "  3    -0.18314      0.5305988085889202   3.323961e-03      0.0355826520877702\n",
      "  4    -0.09126      0.5487488825747814   8.365522e-04      0.0181500739858612\n",
      "  5    -0.04555      0.5579153030281038   2.098384e-04      0.0091664204533224\n",
      "  6    -0.02276      0.5625215706913647   5.254747e-05      0.0046062676632609\n",
      "  7    -0.01137      0.5648304952776271   1.314787e-05      0.0023089245862624\n",
      "  8    -0.00569      0.5659864085549946   3.288345e-06      0.0011559132773675\n",
      "  9    -0.00284      0.5665647283514305   8.222583e-07      0.0005783197964359\n",
      " 10    -0.00142      0.5668539790905128   2.055861e-07      0.0002892507390824\n",
      " 11    -0.00071      0.5669986271766673   5.139922e-08      0.0001446480861544\n",
      " 12    -0.00036      0.5670709568998106   1.285014e-08      0.0000723297231433\n",
      " 13    -0.00018      0.5671071231813981   3.212577e-09      0.0000361662815875\n",
      " 14    -0.00009      0.5671252066776159   8.031495e-10      0.0000180834962178\n",
      " 15    -0.00004      0.5671342485140862   2.007881e-10      0.0000090418364703\n",
      " 16    -0.00002      0.5671387694550161   5.019707e-11      0.0000045209409298\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5671387694550161"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(a)\n",
    "f = lambda x: x**2 - 2*x*np.exp(-x) + np.exp(-2*x)\n",
    "fp = lambda x: 2*np.exp(-2*x)*(np.exp(x) + 1)*(np.exp(x)*x - 1)\n",
    "newton_method_stop2(0.3,f,fp,1e-5,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter      grad         root:(x,_)           root:(_,y)        interval length\n",
      "------------------------------------------------------------------------------\n",
      "  1     0.00217     -1.1786828328725436   1.279900e-04\n",
      "  2     0.00092     -1.2376200000887663   4.047965e-05      0.0589371672162227\n",
      "  3     0.00039     -1.2817913472216889   1.280496e-05      0.0441713471329226\n",
      "  4     0.00016     -1.3149065788863532   4.051027e-06      0.0331152316646643\n",
      "  5     0.00007     -1.3397374059706373   1.281674e-06      0.0248308270842841\n",
      "  6     0.00003     -1.3583581664428563   4.055124e-07      0.0186207604722191\n",
      "  7     0.00001     -1.3723227415318771   1.283036e-07      0.0139645750890207\n",
      "  8     0.00001     -1.3827957530364929   4.059552e-08      0.0104730115046159\n",
      "  9     0.00000     -1.3906503345627994   1.284458e-08      0.0078545815263065\n",
      " 10     0.00000     -1.3965411959453928   4.064088e-09      0.0058908613825934\n",
      " 11     0.00000     -1.4009593103716593   1.285900e-09      0.0044181144262665\n",
      " 12     0.00000     -1.4042728827302866   4.068661e-10      0.0033135723586273\n",
      " 13     0.00000     -1.4067580559450539   1.287349e-10      0.0024851732147673\n",
      " 14     0.00000     -1.4086219333745069   4.073242e-11      0.0018638774294530\n",
      " 15     0.00000     -1.4100198364844072   1.288791e-11      0.0013979031099003\n",
      " 16     0.00000     -1.4110682536052201   4.077849e-12      0.0010484171208129\n",
      " 17     0.00000     -1.4118545617307952   1.290190e-12      0.0007863081255750\n",
      " 18     0.00000     -1.4124442478610790   4.082290e-13      0.0005896861302839\n",
      " 19     0.00000     -1.4128864695578682   1.291189e-13      0.0004422216967892\n",
      " 20     0.00000     -1.4132179343758560   4.085621e-14      0.0003314648179877\n",
      " 21     0.00000     -1.4134663151760201   1.287859e-14      0.0002483808001641\n",
      " 22     0.00000     -1.4136515092306523   4.107825e-15      0.0001851940546322\n",
      " 23     0.00000     -1.4137903220434502   1.110223e-15      0.0001388128127979\n",
      " 24     0.00000     -1.4138781831526088   4.440892e-16      0.0000878611091586\n",
      " 25     0.00000     -1.4139488170922168   1.110223e-16      0.0000706339396079\n",
      " 26     0.00000     -1.4139847160008898   0.000000e+00      0.0000358989086731\n",
      " 27     0.00000     -1.4139847160008898   0.000000e+00      0.0000000000000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1.4139847160008898"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(b)\n",
    "f = lambda x: np.cos(x + 2**0.5) + x*(x/2 + 2**0.5)\n",
    "fp = lambda x: x - np.sin(x + 2**0.5) + 2**0.5\n",
    "newton_method_stop2(-1.1,f,fp,1e-5,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter      grad         root:(x,_)           root:(_,y)        interval length\n",
      "------------------------------------------------------------------------------\n",
      "  1   1670.46877      3.9281203817224708   9.240626e+01\n",
      "  2   707.45522      3.8728028181894754   2.925066e+01      0.0553175635329954\n",
      "  3   303.10091      3.8314565077979177   9.122787e+00      0.0413463103915577\n",
      "  4   131.11907      3.8013583241816207   2.809005e+00      0.0300981836162970\n",
      "  5    57.15513      3.7799350098217919   8.559359e-01      0.0214233143598288\n",
      "  6    25.05798      3.7649593487547013   2.587117e-01      0.0149756610670906\n",
      "  7    11.03217      3.7546348218974384   7.772826e-02      0.0103245268572629\n",
      "  8     4.87160      3.7475892211112494   2.325202e-02      0.0070456007861890\n",
      "  9     2.15568      3.7428162429994458   6.934561e-03      0.0047729781118035\n",
      " 10     0.95525      3.7395993586017480   2.063773e-03      0.0032168843976979\n",
      " 11     0.42371      3.7374388973757022   6.133084e-04      0.0021604612260457\n",
      " 12     0.18806      3.7359914253673323   1.820839e-04      0.0014474720083699\n",
      " 13     0.08351      3.7350232265386132   5.402294e-05      0.0009681988287191\n",
      " 14     0.03709      3.7343763202789830   1.602108e-05      0.0006469062596302\n",
      " 15     0.01648      3.7339444070597558   4.749832e-06      0.0004319132192272\n",
      " 16     0.00732      3.7336561778350950   1.407956e-06      0.0002882292246609\n",
      " 17     0.00325      3.7334638923629315   4.173198e-07      0.0001922854721634\n",
      " 18     0.00145      3.7333356307488743   1.236913e-07      0.0001282616140572\n",
      " 19     0.00064      3.7332500717343184   3.664172e-08      0.0000855590145559\n",
      " 20     0.00029      3.7331930094692956   1.079752e-08      0.0000570622650229\n",
      " 21     0.00013      3.7331551359148243   3.230525e-09      0.0000378735544713\n",
      " 22     0.00006      3.7331297169957813   9.313226e-10      0.0000254189190430\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.7331297169957813"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(c)\n",
    "f = lambda x: np.exp(3*x) - 27*x**6 + 27*(x**4)*np.exp(x) - 9*(x**2)*np.exp(2*x)\n",
    "fp = lambda x: 3*(np.exp(x) - 6*x)*(np.exp(x) - 3*x**2)**2\n",
    "newton_method_stop2(4,f,fp,1e-5,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If p is a root of $f(x) = 0$ with multiplicity $m$, then\n",
    "$$f(x) = g(x)(h(x) - h(p))^m \\mbox{ where } g(p) \\neq 0.$$\n",
    "\n",
    "This implies that\n",
    "\n",
    "$\\begin{align*}\n",
    "f'(x) &= g'(x)(h(x) - h(p))^m + mg(x)h'(x)(h(x) - h(p))^{m-1} \\\\\n",
    "&= (g'(x)(h(x) - h(p)) - mg(x)(h'(x))(h(x) - h(p)^{m-1}) \\\\\n",
    "&= g_1(x)(h(x) - h(p))^{m-1}.\n",
    "\\end{align*}$\n",
    "\n",
    "Therefore, $f^{(k)}(x) = g_k(x)(h(x) - h(p))^{m-k}$ for $1 \\leq k \\leq m-1$.\n",
    "\n",
    "Therefore, $f(p) = 0, f'(p) = 0, \\ldots, f^{(m-1)}(p) = 0.$\n",
    "\n",
    "According to Burden and Faires, quadratic convergence might not occur if $f(p) = 0$ and $f'(p) = 0$.\n",
    "\n",
    "If we let $g(x) = x - \\phi(x)f(x)$, then $g'(x) = 1 - \\phi'(x)f(x) -  \\phi(x)f'(x)$. However, if $f'(p) = 0$, then $g'(x) = 1$ for all function $\\phi$. $g'(x) \\neq 0$ implies linear convergence of any fixed point iteration scheme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Newton's method with multiplicity of root correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_method_stop2_mulcorrection(x0,f,fp,fpp,tol,N):\n",
    "    F = f(x0)\n",
    "    Fp = fp(x0)\n",
    "    Fpp = fpp(x0)\n",
    "    iteration = 1\n",
    "    print (\"iter      divisor         root:(x,_)           root:(_,y)        interval length\")\n",
    "    print (\"------------------------------------------------------------------------------\")\n",
    "    x = x0 - Fp*F/(Fp**2 - F*Fpp) #We run one iteration to get a x1 and (x0-x1) value.\n",
    "    x1 = x0 #x1 is the p_{n-1} value; sorry its a misnomer, I'm lazy to change it.\n",
    "    x0 = x\n",
    "    F = f(x0)\n",
    "    Fp = fp(x0)\n",
    "    Fpp = fpp(x0)\n",
    "    print('{:>3d}  {:> 10.5f}  {:> 22.16f}  {:>13.6e}'.format(1, Fp, x, np.abs(F), np.abs(x0-x1)))\n",
    "    iteration = iteration + 1\n",
    "    while (iteration<=N) & (np.abs(x0-x1)>np.abs(tol*x1)):\n",
    "        x = x0 - Fp*F/(Fp**2 - F*Fpp)\n",
    "        x1 = x0\n",
    "        x0 = x\n",
    "        F = f(x0)\n",
    "        Fp = fp(x0)\n",
    "        Fpp = fpp(x0)\n",
    "        print('{:>3d}  {:> 10.5f}  {:> 22.16f}  {:>13.6e}  {:> 22.16f}'.format(iteration, (Fp**2 - F*Fpp), x, np.abs(F),np.abs(x0-x1)))\n",
    "        iteration = iteration + 1\n",
    "    if np.abs(x-x0)<=np.abs(tol*x1):\n",
    "        return x0\n",
    "    else:\n",
    "        print(\"Method failed to converge. Try harder!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Bisection Method but with results stored in an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bisection_method_withresults(a,b,f,tol,N):\n",
    "    FA,FB = f(a), f(b)\n",
    "    results=[]\n",
    "    iteration = 1\n",
    "    if FA*FB<0:\n",
    "        print (\"iter      a           b            root:(x,_)           root:(_,y)\")\n",
    "        print (\"------------------------------------------------------------------\")\n",
    "        p = (a + b)/2\n",
    "        FP = f(p)\n",
    "        while (np.abs((b-a)/2)>tol) & (iteration <= N):\n",
    "            if FA*FP<0:\n",
    "                b=p\n",
    "                FB=FP\n",
    "            else:\n",
    "                a=p\n",
    "                FA=FP\n",
    "            p = (a+b)/2\n",
    "            FP = f(p)\n",
    "            print('{:>3d}  {:> 10.5f}  {:> 10.5f}  {:> 22.16f}  {:>13.6e}'.format(iteration, a, b, p, abs(FP)))\n",
    "            results.append(p)\n",
    "            iteration = iteration + 1\n",
    "        if np.abs((b-a)/2)>tol:\n",
    "            print(\"Method failed to converge\")\n",
    "        else:\n",
    "            return p, results\n",
    "    else:\n",
    "             print(\"Cannot ensure existence of root\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter      divisor         root:(x,_)           root:(_,y)        interval length\n",
      "------------------------------------------------------------------------------\n",
      "  1     0.08112      0.5838083972615007   6.779926e-04\n",
      "  2     0.00000      0.5671927362614900   6.004397e-09      0.0166156610000107\n",
      "  3     0.00000      0.5671432908508617   5.551115e-17      0.0000494454106283\n",
      "  4    -0.00000      0.5671432912844749   5.551115e-17      0.0000000004336133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5671432912844749"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(a)\n",
    "f = lambda x: x**2 - 2*x*np.exp(-x) + np.exp(-2*x)\n",
    "fp = lambda x: 2*np.exp(-2*x)*(np.exp(x) + 1)*(np.exp(x)*x - 1)\n",
    "fpp = lambda x: -2*np.exp(-x)*(x-2) + 4*np.exp(-2*x) + 2\n",
    "newton_method_stop2_mulcorrection(0.3,f,fp,fpp,1e-5,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter      divisor         root:(x,_)           root:(_,y)        interval length\n",
      "------------------------------------------------------------------------------\n",
      "  1     0.00000     -1.4131816691807593   4.718448e-14\n",
      "  2     0.00000     -1.4142085583550834   1.110223e-16      0.0010268891743241\n",
      "  3     0.00000     -1.4142085583550834   1.110223e-16      0.0000000000000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1.4142085583550834"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(b)\n",
    "f = lambda x: np.cos(x + 2**0.5) + x*(x/2 + 2**0.5)\n",
    "fp = lambda x: x - np.sin(x + 2**0.5) + 2**0.5\n",
    "fpp = lambda x: 1 - np.cos(x + 2**0.5)\n",
    "newton_method_stop2_mulcorrection(-1.1,f,fp,fpp,1e-5,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter      divisor         root:(x,_)           root:(_,y)        interval length\n",
      "------------------------------------------------------------------------------\n",
      "  1    65.06103      3.6720356968913230   1.403597e+00\n",
      "  2     0.02357      3.7295805255521182   3.100712e-04      0.0575448286607951\n",
      "  3     0.00000      3.7330677255408902   2.910383e-11      0.0034871999887720\n",
      "  4    -0.00000      3.7330640655685072   5.820766e-11      0.0000036599723829\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.7330640655685072"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(c)\n",
    "f = lambda x: np.exp(3*x) - 27*x**6 + 27*(x**4)*np.exp(x) - 9*(x**2)*np.exp(2*x)\n",
    "fp = lambda x: 3*(np.exp(x) - 6*x)*(np.exp(x) - 3*x**2)**2\n",
    "fpp = lambda x: 6*(np.exp(x) - 3*x**2)*(np.exp(x) - 6*x)**2 + 3*(np.exp(x) - 6)*(np.exp(x) - 3*x**2)**2\n",
    "newton_method_stop2_mulcorrection(4,f,fp,fpp,1e-5,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all three functions in Q1, Newton's Method with multiplicity of root correction results in faster convergence. In fact, for 1(c) and especially 1(b), the convergence appears to be faster than quadratic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the sequence $\\displaystyle\\left(p_{n+1} = p_n^3 \\mbox{ with } p_0 = 0.5\\right)_{n \\in \\mathbb{N}^0},$ i.e. $\\displaystyle\\left(2^{-3^n}\\right)_{n \\in \\mathbb{N}^0}$. This sequence converges to $0$.\n",
    "\n",
    "Let $\\alpha = 3$ in $\\displaystyle\\lim_{n\\rightarrow\\infty}\\frac{\\mid p_{n+1} - p \\mid}{\\mid p_{n} - p \\mid^\\alpha} = \\lambda$. $\\displaystyle\\lim_{n\\rightarrow\\infty}\\frac{\\mid p_{n+1}\\mid}{\\mid p_{n}\\mid^3} = \\lambda \\implies \\lim_{n\\rightarrow\\infty}\\frac{\\mid p_{n}\\mid^3}{\\mid p_{n}\\mid^3} = \\lambda \\implies \\lambda = 1$. \n",
    "Therefore, the sequence converges to $0$ with order $3$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error of the bisection algorithm is the length of the interval which is given by the sequence $\\displaystyle\\left(p_{n+1} = 0.5p_n \\mbox{ with } p_0 = \\mbox{some } \\mathbb{R}^+\\right)$, i.e. $\\displaystyle\\left(\\frac{a}{2^n} \\mbox{ for some } a\\in\\mathbb{R}^+\\right)_{n \\in \\mathbb{N}^0}$. This sequence converges to $0$.\n",
    "\n",
    "Let $\\alpha = 1$ in $\\displaystyle\\lim_{n\\rightarrow\\infty}\\frac{\\mid p_{n+1} - p \\mid}{\\mid p_{n} - p \\mid^\\alpha} = \\lambda$. $\\displaystyle\\lim_{n\\rightarrow\\infty}\\frac{\\mid p_{n+1}\\mid}{\\mid p_{n}\\mid} = \\lambda \\implies \\lim_{n\\rightarrow\\infty}\\frac{\\mid 0.5p_{n}\\mid}{\\mid p_{n}\\mid} = \\lambda \\implies \\lambda = 0.5$. \n",
    "Therefore, the sequence converges linearly to $0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter      a           b            root:(x,_)           root:(_,y)\n",
      "------------------------------------------------------------------\n",
      "  1     3.00000     4.00000      3.5000000000000000   4.801216e+01\n",
      "  2     3.50000     4.00000      3.7500000000000000   3.711999e-02\n",
      "  3     3.50000     3.75000      3.6250000000000000   6.828201e+00\n",
      "  4     3.62500     3.75000      3.6875000000000000   6.100351e-01\n",
      "  5     3.68750     3.75000      3.7187500000000000   2.067434e-02\n",
      "  6     3.71875     3.75000      3.7343750000000000   1.597218e-05\n",
      "  7     3.71875     3.73438      3.7265625000000000   1.987165e-03\n",
      "  8     3.72656     3.73438      3.7304687500000000   1.291051e-04\n",
      "  9     3.73047     3.73438      3.7324218750000000   2.071203e-06\n",
      " 10     3.73242     3.73438      3.7333984375000000   2.384768e-07\n",
      " 11     3.73242     3.73340      3.7329101562500000   3.518653e-08\n",
      " 12     3.73291     3.73340      3.7331542968750000   3.085006e-09\n",
      " 13     3.73291     3.73315      3.7330322265625000   7.566996e-10\n",
      " 14     3.73303     3.73315      3.7330932617187500   0.000000e+00\n",
      " 15     3.73309     3.73315      3.7331237792968750   6.693881e-10\n",
      " 16     3.73312     3.73315      3.7331390380859375   1.600711e-09\n",
      " 17     3.73314     3.73315      3.7331466674804688   2.270099e-09\n",
      " 18     3.73315     3.73315      3.7331504821777344   2.706656e-09\n",
      " 19     3.73315     3.73315      3.7331523895263672   2.881279e-09\n",
      " 20     3.73315     3.73315      3.7331533432006836   3.026798e-09\n",
      " 21     3.73315     3.73315      3.7331538200378418   3.055902e-09\n",
      " 22     3.73315     3.73315      3.7331540584564209   3.172318e-09\n",
      " 23     3.73315     3.73315      3.7331541776657104   3.143214e-09\n",
      " 24     3.73315     3.73315      3.7331542372703552   3.085006e-09\n",
      " 25     3.73315     3.73315      3.7331542670726776   3.143214e-09\n",
      " 26     3.73315     3.73315      3.7331542819738388   3.114110e-09\n",
      " 27     3.73315     3.73315      3.7331542894244194   3.143214e-09\n",
      " 28     3.73315     3.73315      3.7331542931497097   3.114110e-09\n",
      " 29     3.73315     3.73315      3.7331542950123549   3.085006e-09\n",
      " 30     3.73315     3.73315      3.7331542959436774   3.085006e-09\n",
      " 31     3.73315     3.73315      3.7331542964093387   3.114110e-09\n",
      " 32     3.73315     3.73315      3.7331542966421694   3.085006e-09\n",
      " 33     3.73315     3.73315      3.7331542967585847   3.143214e-09\n",
      " 34     3.73315     3.73315      3.7331542968167923   3.114110e-09\n",
      " 35     3.73315     3.73315      3.7331542968458962   3.114110e-09\n",
      " 36     3.73315     3.73315      3.7331542968604481   3.114110e-09\n",
      " 37     3.73315     3.73315      3.7331542968677240   3.143214e-09\n",
      " 38     3.73315     3.73315      3.7331542968713620   3.085006e-09\n",
      " 39     3.73315     3.73315      3.7331542968731810   3.172318e-09\n",
      " 40     3.73315     3.73315      3.7331542968740905   3.143214e-09\n",
      " 41     3.73315     3.73315      3.7331542968745453   3.055902e-09\n",
      " 42     3.73315     3.73315      3.7331542968747726   3.143214e-09\n",
      " 43     3.73315     3.73315      3.7331542968748863   3.172318e-09\n",
      " 44     3.73315     3.73315      3.7331542968749432   3.172318e-09\n",
      " 45     3.73315     3.73315      3.7331542968749716   3.085006e-09\n",
      " 46     3.73315     3.73315      3.7331542968749858   3.143214e-09\n",
      " 47     3.73315     3.73315      3.7331542968749929   3.143214e-09\n",
      " 48     3.73315     3.73315      3.7331542968749964   3.085006e-09\n",
      " 49     3.73315     3.73315      3.7331542968749982   3.143214e-09\n",
      " 50     3.73315     3.73315      3.7331542968749991   3.085006e-09\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = lambda x: np.exp(3*x) - 27*x**6 + 27*(x**4)*np.exp(x) - 9*(x**2)*np.exp(2*x)\n",
    "p, results = bisection_method_withresults(3,5,f,1e-15,100)\n",
    "plot=[[],[]]\n",
    "for i in range(0, len(results)-1):\n",
    "    plot[0].append(np.abs(results[i]-p))\n",
    "    plot[1].append(np.abs(results[i+1]-p))\n",
    "plt.loglog(plot[0],plot[1], '.') #Apart from a few anomalous plots, the convergence is linear.\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose sequence $(p_n)$ converges to $p$ of order $\\alpha$ and $n$ is large. Therefore, $\\displaystyle\\frac{| p_{n+1} - p|}{| p_n - p|^\\alpha} \\approx \\lambda \\implies \\frac{| p_n - p|}{| p_{n-1} - p|^\\alpha} \\approx \\lambda$. \n",
    "\n",
    "$\\displaystyle\\frac{| p_n - p|}{| p_{n-1} - p|^\\alpha} \\approx \\lambda \\implies \\left(\\frac{1}{\\lambda}| p_n - p|\\right)^{1/\\alpha} \\approx | p_{n-1} - p|$.\n",
    "\n",
    "Given $| p_{n+1} - p| \\approx C | p_n - p|| p_{n-1} - p|$, we have $\\displaystyle| p_{n+1} - p| \\approx C\\left(\\frac{1}{\\lambda}\\right)^{1/\\alpha}|p_n - p|^{1/\\alpha}|p_n - p| \\implies \\frac{| p_{n+1} - p|}{| p_n - p|^{1+1/\\alpha}} \\approx C\\left(\\frac{1}{\\lambda}\\right)^{1/\\alpha}$.\n",
    "\n",
    "Since $\\displaystyle C\\left(\\frac{1}{\\lambda}\\right)^{1/\\alpha}$ is a positive constant, $\\displaystyle\\frac{1+\\alpha}{\\alpha} = \\alpha \\implies \\alpha^2 - \\alpha - 1 = 0 \\implies \\alpha = \\frac{1 + \\sqrt{5}}{2} \\approx 1.618$ since $\\alpha > 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accelerating Convergence: Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Newton's Method (with $|p_n - p_{n-1}| \\leq \\epsilon$ stopping criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_method_stop1(x0,f,fp,tol,N):\n",
    "    F = f(x0)\n",
    "    Fp = fp(x0)\n",
    "    results=[]\n",
    "    iteration = 1\n",
    "    print (\"iter      grad         root:(x,_)           root:(_,y)        interval length\")\n",
    "    print (\"------------------------------------------------------------------------------\")\n",
    "    x = (Fp*x0 - F)/Fp #We run one iteration to get a (x0-x1) value, though if we immediately get the root, we will just return it.\n",
    "    results.append(x)\n",
    "    x1 = x0 #x1 is the p_{n-1} value; sorry its a misnomer, I'm lazy to change it.\n",
    "    x0 = x\n",
    "    F = f(x0)\n",
    "    Fp = fp(x0)\n",
    "    print('{:>3d}  {:> 10.5f}  {:> 22.16f}  {:>13.6e}  {:> 22.16f}'.format(1, Fp, x, np.abs(F),np.abs(x0-x1)))\n",
    "    if np.abs(F)<=tol:\n",
    "        return x0\n",
    "    else:\n",
    "        iteration = iteration + 1\n",
    "        while (iteration<=N) & (np.abs(x0-x1)>tol):\n",
    "            x = (Fp*x0 - F)/Fp\n",
    "            results.append(x)\n",
    "            x1 = x0\n",
    "            x0 = x\n",
    "            F = f(x0)\n",
    "            Fp = fp(x0)\n",
    "            print('{:>3d}  {:> 10.5f}  {:> 22.16f}  {:>13.6e}  {:> 22.16f}'.format(iteration, Fp, x, np.abs(F),np.abs(x0-x1)))\n",
    "            iteration = iteration + 1\n",
    "        if np.abs(x-x0)<=tol:\n",
    "            return x0, results\n",
    "        else:\n",
    "            print(\"Method failed to converge. Try harder!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter      grad         root:(x,_)           root:(_,y)        interval length\n",
      "------------------------------------------------------------------------------\n",
      "  1     0.23802     -0.0511421365733425   9.211568e-03      0.0511421365733425\n",
      "  2     0.10164     -0.0898424758150268   2.886715e-03      0.0387003392416843\n",
      "  3     0.04388     -0.1182447360258248   8.915830e-04      0.0284022602107980\n",
      "  4     0.01910     -0.1385655958400078   2.721970e-04      0.0203208598141830\n",
      "  5     0.00837     -0.1528161929692974   8.237076e-05      0.0142505971292896\n",
      "  6     0.00368     -0.1626602525902589   2.476594e-05      0.0098440596209615\n",
      "  7     0.00163     -0.1693861756223201   7.412004e-06      0.0067259230320612\n",
      "  8     0.00072     -0.1739460644747723   2.211159e-06      0.0045598888524522\n",
      "  9     0.00032     -0.1770208137708657   6.581784e-07      0.0030747492960934\n",
      " 10     0.00014     -0.1790864552280062   1.956199e-07      0.0020656414571405\n",
      " 11     0.00006     -0.1804706766816483   5.808176e-08      0.0013842214536422\n",
      " 12     0.00003     -0.1813966891506640   1.723331e-08      0.0009260124690156\n",
      " 13     0.00001     -0.1820154613767330   5.110905e-09      0.0006187722260690\n",
      " 14     0.00001     -0.1824286147391486   1.515281e-09      0.0004131533624157\n",
      " 15     0.00000     -0.1827043349434589   4.491577e-10      0.0002757202043102\n",
      " 16     0.00000     -0.1828882751315548   1.331205e-10      0.0001839401880959\n"
     ]
    }
   ],
   "source": [
    "f = lambda x: np.exp(6*x) + 3*(np.log(2)**2)*np.exp(2*x) - np.log(8)*np.exp(4*x) - np.log(2)**3\n",
    "fp = lambda x: 6*np.exp(6*x) + 6*(np.log(2)**2)*np.exp(2*x) - 4*np.log(8)*np.exp(4*x)\n",
    "newton_method_stop1(0,f,fp,0.0002,100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aitken's Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter      grad         root:(x,_)           root:(_,y)        interval length\n",
      "------------------------------------------------------------------------------\n",
      "  1     0.23802     -0.0511421365733425   9.211568e-03      0.0511421365733425\n",
      "  2     0.10164     -0.0898424758150268   2.886715e-03      0.0387003392416843\n",
      "  3     0.04388     -0.1182447360258248   8.915830e-04      0.0284022602107980\n",
      "  4     0.01910     -0.1385655958400078   2.721970e-04      0.0203208598141830\n",
      "  5     0.00837     -0.1528161929692974   8.237076e-05      0.0142505971292896\n",
      "  6     0.00368     -0.1626602525902589   2.476594e-05      0.0098440596209615\n",
      "  7     0.00163     -0.1693861756223201   7.412004e-06      0.0067259230320612\n",
      "  8     0.00072     -0.1739460644747723   2.211159e-06      0.0045598888524522\n",
      "  9     0.00032     -0.1770208137708657   6.581784e-07      0.0030747492960934\n",
      " 10     0.00014     -0.1790864552280062   1.956199e-07      0.0020656414571405\n",
      " 11     0.00006     -0.1804706766816483   5.808176e-08      0.0013842214536422\n",
      " 12     0.00003     -0.1813966891506640   1.723331e-08      0.0009260124690156\n",
      " 13     0.00001     -0.1820154613767330   5.110905e-09      0.0006187722260690\n",
      " 14     0.00001     -0.1824286147391486   1.515281e-09      0.0004131533624157\n",
      " 15     0.00000     -0.1827043349434589   4.491577e-10      0.0002757202043102\n",
      " 16     0.00000     -0.1828882751315548   1.331205e-10      0.0001839401880959\n",
      "\n",
      "  0      -0.051142136573342        -0.064445431703108\n",
      "  1      -0.089842475815027        -0.094138710877246\n",
      "  2      -0.118244736025825        -0.119947151078497\n",
      "  3      -0.138565595840008        -0.139286918410616\n",
      "  4      -0.152816192969297        -0.153130056437536\n",
      "  5      -0.162660252590259        -0.162798389689639\n",
      "  6      -0.169386175622320        -0.169447284009083\n",
      "  7      -0.173946064474772        -0.173973161206561\n",
      "  8      -0.177020813770866        -0.177032842520221\n",
      "  9      -0.179086455228006        -0.179091797957426\n",
      " 10      -0.180470676681648        -0.180473050390800\n",
      " 11      -0.181396689150664        -0.181397743916850\n",
      " 12      -0.182015461376733        -0.182015930104172\n",
      " 13      -0.182428614739149        -0.182428823046690\n"
     ]
    }
   ],
   "source": [
    "f = lambda x: np.exp(6*x) + 3*(np.log(2)**2)*np.exp(2*x) - np.log(8)*np.exp(4*x) - np.log(2)**3\n",
    "fp = lambda x: 6*np.exp(6*x) + 6*(np.log(2)**2)*np.exp(2*x) - 4*np.log(8)*np.exp(4*x)\n",
    "p, results = newton_method_stop1(0,f,fp,0.0002,100)\n",
    "results_Atkin=np.zeros(len(results))\n",
    "print(\"\")\n",
    "for n in range(1,len(results)):\n",
    "    if n>=2:\n",
    "        results_Atkin[n-2] = results[n-2] - (results[n-1]-results[n-2])**2/(results[n]-2*results[n-1]-results[n-2])\n",
    "        print(\"%3d      % 3.15f        % 3.15f\" %(n-2,results[n-2],results_Atkin[n-2])) #There is almost no improvement in convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolation: Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Lagrange Polynomial Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L(xvals,kk,x):\n",
    "    value = np.ones(x.size)\n",
    "    n = xvals.size\n",
    "    for ii in range(0,n):\n",
    "        if ii != kk:\n",
    "            value *= (x-xvals[ii])/(xvals[kk]-xvals[ii])\n",
    "    return value\n",
    "    \n",
    "def p_Lagrange(xvals,yvals,x):\n",
    "    n = yvals.size\n",
    "    pLagrange = np.zeros(x.size)\n",
    "    for kk in range(0,n):\n",
    "        pLagrange += yvals[kk]*L(xvals,kk,x)\n",
    "    return pLagrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate = 0.898; Absolute Error = 2.347e-03\n"
     ]
    }
   ],
   "source": [
    "# 1(a)\n",
    "f = lambda x: np.cos(x)\n",
    "xvals = np.array([0, .6, .9])\n",
    "x = np.array([0.45])\n",
    "yvals = f(xvals)\n",
    "estimate = p_Lagrange(xvals,yvals,x)[0] #Estimate\n",
    "abs_error = np.abs(estimate - f(x[0])) #\n",
    "print('Estimate = {:<1.3f}; Absolute Error = {:<1.3e}'.format(estimate,abs_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate = 1.203; Absolute Error = 7.357e-04\n"
     ]
    }
   ],
   "source": [
    "# 1(b)\n",
    "f = lambda x: np.sqrt(1+x)\n",
    "xvals = np.array([0, .6, .9])\n",
    "x = np.array([0.45])\n",
    "yvals = f(xvals)\n",
    "estimate = p_Lagrange(xvals,yvals,x)[0] #Estimate\n",
    "abs_error = np.abs(estimate - f(x[0])) #\n",
    "print('Estimate = {:<1.3f}; Absolute Error = {:<1.3e}'.format(estimate,abs_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate = 0.368; Absolute Error = 3.273e-03\n"
     ]
    }
   ],
   "source": [
    "# 1(c)\n",
    "f = lambda x: np.log(np.abs(1+x))\n",
    "xvals = np.array([0, .6, .9])\n",
    "x = np.array([0.45])\n",
    "yvals = f(xvals)\n",
    "estimate = p_Lagrange(xvals,yvals,x)[0] #Estimate\n",
    "abs_error = np.abs(estimate - f(x[0])) #\n",
    "print('Estimate = {:<1.3f}; Absolute Error = {:<1.3e}'.format(estimate,abs_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate = 0.455; Absolute Error = 2.844e-02\n"
     ]
    }
   ],
   "source": [
    "# 1(d)\n",
    "f = lambda x: np.tan(x)\n",
    "xvals = np.array([0, .6, .9])\n",
    "x = np.array([0.45])\n",
    "yvals = f(xvals)\n",
    "estimate = p_Lagrange(xvals,yvals,x)[0] #Estimate\n",
    "abs_error = np.abs(estimate - f(x[0])) #\n",
    "print('Estimate = {:<1.3f}; Absolute Error = {:<1.3e}'.format(estimate,abs_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\displaystyle P'_n(x) = \\sum_{k=0}^n f(x_k)L'_{n,k}(x)$ since $f(x_k)$ is just a constant. We want to find a formula for $L'_{n,k}(x)$.\n",
    "\n",
    "$\\displaystyle\\ln(L_{n,k}(x)) = \\sum_{j=0,j\\neq k}^n \\ln\\frac{x - x_j}{x_k - x_j} \\implies \\frac{d}{dx}\\ln(L_{n,k}(x)) = \\frac{L'_{n,k}(x)}{L_{n,k}(x)} = \\sum_{j=0,j\\neq k}^n \\frac{1}{x_k - x_j}\\frac{x_k - x_j}{x - x_j} = \\sum_{j=0,j\\neq k}^n \\frac{1}{x - x_j}$.\n",
    "\n",
    "Therefore, $\\displaystyle L'_{n,k}(x) = L_{n,k}(x)\\left(\\sum_{j=0,j\\neq k}^n \\frac{1}{x - x_j}\\right)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L(xvals,kk,x):\n",
    "    value = np.ones(x.size)\n",
    "    n = xvals.size\n",
    "    for ii in range(0,n):\n",
    "        if ii != kk:\n",
    "            value *= (x-xvals[ii])/(xvals[kk]-xvals[ii])\n",
    "    return value\n",
    "\n",
    "def LpSum(xvals,kk,x):\n",
    "    lval = np.zeros(x.size)\n",
    "    n = xvals.size\n",
    "    for ii in range(0,n):\n",
    "        if ii != kk:\n",
    "            lval += 1/(x-xvals[ii])\n",
    "    return lval\n",
    "\n",
    "def p_LagrangeP(xvals,fvals,x):\n",
    "    n = fvals.size\n",
    "    pLagrange = np.zeros(x.size)\n",
    "    for kk in range(0,n):\n",
    "        pLagrange += fvals[kk]*L(xvals,kk,x)*LpSum(xvals,kk,x)\n",
    "    return pLagrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate = -0.420; Absolute Error = 1.453e-02\n"
     ]
    }
   ],
   "source": [
    "# 2(a)\n",
    "f = lambda x: np.cos(x)\n",
    "fp = lambda x: -np.sin(x)\n",
    "xvals = np.array([0, .6, .9])\n",
    "x = np.array([0.45])\n",
    "yvals = f(xvals)\n",
    "estimate = p_LagrangeP(xvals,yvals,x)[0] #Estimate\n",
    "abs_error = np.abs(estimate - fp(x[0])) #\n",
    "print('Estimate = {:<1.3f}; Absolute Error = {:<1.3e}'.format(estimate,abs_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate = 0.420; Absolute Error = 5.222e-03\n"
     ]
    }
   ],
   "source": [
    "# 2(b)\n",
    "f = lambda x: np.sqrt(1+x)\n",
    "fp = lambda x: 0.5*np.sqrt(1/(1+x))\n",
    "xvals = np.array([0, .6, .9])\n",
    "x = np.array([0.45])\n",
    "yvals = f(xvals)\n",
    "estimate = p_LagrangeP(xvals,yvals,x)[0] #Estimate\n",
    "abs_error = np.abs(estimate - fp(x[0])) #\n",
    "print('Estimate = {:<1.3f}; Absolute Error = {:<1.3e}'.format(estimate,abs_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate = 0.713; Absolute Error = 2.352e-02\n"
     ]
    }
   ],
   "source": [
    "# 2(c)\n",
    "f = lambda x: np.log(np.abs(1+x))\n",
    "fp = lambda x: 1/(1+x)\n",
    "xvals = np.array([0, .6, .9])\n",
    "x = np.array([0.45])\n",
    "yvals = f(xvals)\n",
    "estimate = p_LagrangeP(xvals,yvals,x)[0] #Estimate\n",
    "abs_error = np.abs(estimate - fp(x[0])) #\n",
    "print('Estimate = {:<1.3f}; Absolute Error = {:<1.3e}'.format(estimate,abs_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate = 1.400; Absolute Error = 1.668e-01\n"
     ]
    }
   ],
   "source": [
    "# 2(d)\n",
    "f = lambda x: np.tan(x)\n",
    "fp = lambda x: 1/(np.cos(x)**2)\n",
    "xvals = np.array([0, .6, .9])\n",
    "x = np.array([0.45])\n",
    "yvals = f(xvals)\n",
    "estimate = p_LagrangeP(xvals,yvals,x)[0] #Estimate\n",
    "abs_error = np.abs(estimate - fp(x[0])) #\n",
    "print('Estimate = {:<1.3f}; Absolute Error = {:<1.3e}'.format(estimate,abs_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for Cubic Spline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cubic_spline_coeffs(xvals,yvals):\n",
    "\n",
    "    n = xvals.size - 1\n",
    "    h = xvals[1:]-xvals[0:-1]\n",
    "\n",
    "    d0 = np.hstack([1,2*(h[0:-1]+h[1:]),1])\n",
    "    d1 = np.hstack([0,h[1:]])\n",
    "    dm1 = np.hstack([h[0:-1],0])\n",
    "    # create the \"A\" matrix by using the np.diag command\n",
    "    A = np.diag(d0) + np.diag(d1,1)+ np.diag(dm1,-1)\n",
    "\n",
    "    \n",
    "    # create the right-hand-side of A*x = b\n",
    "    # recall that a_j = y_j\n",
    "    aVec = yvals\n",
    "    rhs = np.hstack([0,(3./h[1:])*(aVec[2:]-aVec[1:-1])-(3/h[0:-1])*(aVec[1:-1]-aVec[0:-2]),0])\n",
    "    \n",
    "    # use the linalg.solve command to solve Ax = b  \n",
    "    cVec = np.linalg.solve(A,rhs)\n",
    "\n",
    "    \n",
    "    # use the remaining formula to determine d_j and b_j\n",
    "    dVec = (cVec[1:]-cVec[0:-1])/(3*h)\n",
    "    bVec = 1/h*(aVec[1:] - aVec[0:-1]) - h/3*(2*cVec[0:-1]+cVec[1:])\n",
    "    \n",
    "    # stack all of the coefficients into a matrix so that the coefficients are in the form \n",
    "    #            a_0, a_1, ...\n",
    "    #            b_0, b_1, ...\n",
    "    #            c_0, c_1, ...\n",
    "    #            d_0, d_1, ...\n",
    "    \n",
    "    SCoeffs = np.vstack([aVec[0:n], bVec[0:n], cVec[0:n], dVec[0:n]])\n",
    "    return SCoeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cubic_spline_f(x, coeffs, xvals):\n",
    "    n = len(coeffs[0])\n",
    "    ans = 0\n",
    "    for ii in range(0,4):\n",
    "        for jj in range(0,n):\n",
    "            ans += coeffs[ii][jj]*((x-xvals[jj])**ii)*((xvals[jj]<x) and (x<=xvals[jj+1]))\n",
    "    return ans\n",
    "\n",
    "def cubic_spline_fp(x, coeffs, xvals):\n",
    "    n = len(coeffs[0])\n",
    "    ans = 0\n",
    "    for ii in range(1,4):\n",
    "        for jj in range(0,n):\n",
    "            ans += coeffs[ii][jj]*ii*((x-xvals[jj])**(ii-1))*((xvals[jj]<x) and (x<=xvals[jj+1]))\n",
    "    return ans\n",
    "\n",
    "def cubic_spline_fpp(x, coeffs, xvals):\n",
    "    n = len(coeffs[0])\n",
    "    ans = 0\n",
    "    for ii in range(2,4):\n",
    "        for jj in range(0,n):\n",
    "            ans += coeffs[ii][jj]*ii*(ii-1)*((x-xvals[jj])**(ii-2))*((xvals[jj]<x) and (x<=xvals[jj+1]))\n",
    "    return ans\n",
    "\n",
    "def cubic_spline_f_integrate(coeffs, xvals): #xvals demarcate the integration; coeffs must contain ONLY the coeffs involved in the integration.\n",
    "    n = len(coeffs[0])\n",
    "    ans = 0\n",
    "    for kk in range(0,n):\n",
    "        x_l,x_u = xvals[kk], xvals[kk+1]\n",
    "        for ii in range(0,4):\n",
    "            for jj in range(0,n):\n",
    "                ans += coeffs[ii][jj]*(1/(ii+1))*((x_u-xvals[kk+1])**(ii+1)) - coeffs[ii][jj]*(1/(ii+1))*((x_l-xvals[kk])**(ii+1))\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using coefficients from cubic_spline_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integration over [0,1]; actual value = 0\n",
      "0.0\n",
      "\n",
      "\n",
      "f value comparison of spline vs actual\n",
      "6.123233995736766e-17\n",
      "9.71445146547012e-17\n",
      "3.591217469733354e-17\n",
      "\n",
      "\n",
      "fp value comparison of spline vs actual\n",
      "-3.2426406871192848\n",
      "-3.141592653589793\n",
      "0.10104803352949165\n",
      "\n",
      "\n",
      "fpp value comparison of spline vs actual\n",
      "-3.552713678800501e-15\n",
      "-6.043389719322356e-16\n",
      "2.9483747068682654e-15\n"
     ]
    }
   ],
   "source": [
    "fp_actual = lambda x: -pi*np.sin(pi*x)\n",
    "fpp_actual = lambda x: -(pi**2)*np.cos(pi*x)\n",
    "\n",
    "f_actual = lambda x: np.cos(np.pi*x)\n",
    "xvals = np.array([0,0.25,0.5,0.75,1])\n",
    "yvals = f_actual(xvals)\n",
    "coeffs = cubic_spline_coeffs(xvals,yvals)\n",
    "\n",
    "print(\"Integration over [0,1]; actual value = 0\")\n",
    "print(cubic_spline_f_integrate(coeffs, xvals))\n",
    "print()\n",
    "print()\n",
    "print(\"f value comparison of spline vs actual\")\n",
    "print(f_actual(0.5))\n",
    "print(cubic_spline_f(0.5,coeffs,xvals))\n",
    "print(np.abs(cubic_spline_f(0.5,coeffs,xvals) - f_actual(0.5)))\n",
    "print()\n",
    "print()\n",
    "print(\"fp value comparison of spline vs actual\")\n",
    "print(cubic_spline_fp(0.5,coeffs,xvals))\n",
    "print(fp_actual(0.5))\n",
    "print(np.abs(cubic_spline_fp(0.5,coeffs,xvals) - fp_actual(0.5)))\n",
    "print()\n",
    "print()\n",
    "print(\"fpp value comparison of spline vs actual\")\n",
    "print(cubic_spline_fpp(0.5,coeffs, xvals))\n",
    "print(fpp_actual(0.5))\n",
    "print(np.abs(cubic_spline_fpp(0.5,coeffs, xvals) - fpp_actual(0.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot of the cubic spline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xplot = np.linspace(0.01,1,100)\n",
    "CSyplot=[]\n",
    "actualyplot = f_actual(xplot)\n",
    "for x in xplot:\n",
    "    CSyplot.append(cubic_spline_f(x,coeffs,xvals))\n",
    "plt.plot(xplot, CSyplot)\n",
    "plt.plot(xplot, actualyplot)\n",
    "plt.grid(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
