{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2\n",
    "\n",
    "## by Dion Ho\n",
    "\n",
    "\n",
    "# Import Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from math import pi\n",
    "from math import factorial\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Newton's Method (with $\\frac{|p_n - p_{n-1}|}{|p_n|} \\leq \\epsilon$ stopping criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_method_stop2(x0,f,fp,tol,N):\n",
    "    F = f(x0)\n",
    "    Fp = fp(x0)\n",
    "    iteration = 1\n",
    "    print (\"iter      grad         root:(x,_)           root:(_,y)        interval length\")\n",
    "    print (\"------------------------------------------------------------------------------\")\n",
    "    x = (Fp*x0 - F)/Fp #We run one iteration to get a x1 and (x0-x1) value.\n",
    "    x1 = x0 #x1 is the p_{n-1} value; sorry its a misnomer, I'm lazy to change it.\n",
    "    x0 = x\n",
    "    F = f(x0)\n",
    "    Fp = fp(x0)\n",
    "    print('{:>3d}  {:> 10.5f}  {:> 22.16f}  {:>13.6e}'.format(1, Fp, x, np.abs(F), np.abs(x0-x1)))\n",
    "    iteration = iteration + 1\n",
    "    while (iteration<=N) & (np.abs(x0-x1)>np.abs(tol*x1)):\n",
    "        x = (Fp*x0 - F)/Fp\n",
    "        x1 = x0\n",
    "        x0 = x\n",
    "        F = f(x0)\n",
    "        Fp = fp(x0)\n",
    "        print('{:>3d}  {:> 10.5f}  {:> 22.16f}  {:>13.6e}  {:> 22.16f}'.format(iteration, Fp, x, np.abs(F),np.abs(x0-x1)))\n",
    "        iteration = iteration + 1\n",
    "    if np.abs(x-x0)<=np.abs(tol*x1):\n",
    "        return x0\n",
    "    else:\n",
    "        print(\"Method failed to converge. Try harder!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter      grad         root:(x,_)           root:(_,y)        interval length\n",
      "------------------------------------------------------------------------------\n",
      "  1    -0.74737      0.4266123640724216   5.112309e-02\n",
      "  2    -0.36873      0.4950161565011499   1.312053e-02      0.0684037924287283\n",
      "  3    -0.18314      0.5305988085889202   3.323961e-03      0.0355826520877702\n",
      "  4    -0.09126      0.5487488825747814   8.365522e-04      0.0181500739858612\n",
      "  5    -0.04555      0.5579153030281038   2.098384e-04      0.0091664204533224\n",
      "  6    -0.02276      0.5625215706913647   5.254747e-05      0.0046062676632609\n",
      "  7    -0.01137      0.5648304952776271   1.314787e-05      0.0023089245862624\n",
      "  8    -0.00569      0.5659864085549946   3.288345e-06      0.0011559132773675\n",
      "  9    -0.00284      0.5665647283514305   8.222583e-07      0.0005783197964359\n",
      " 10    -0.00142      0.5668539790905128   2.055861e-07      0.0002892507390824\n",
      " 11    -0.00071      0.5669986271766673   5.139922e-08      0.0001446480861544\n",
      " 12    -0.00036      0.5670709568998106   1.285014e-08      0.0000723297231433\n",
      " 13    -0.00018      0.5671071231813981   3.212577e-09      0.0000361662815875\n",
      " 14    -0.00009      0.5671252066776159   8.031495e-10      0.0000180834962178\n",
      " 15    -0.00004      0.5671342485140862   2.007881e-10      0.0000090418364703\n",
      " 16    -0.00002      0.5671387694550161   5.019707e-11      0.0000045209409298\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5671387694550161"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(a)\n",
    "f = lambda x: x**2 - 2*x*np.exp(-x) + np.exp(-2*x)\n",
    "fp = lambda x: 2*np.exp(-2*x)*(np.exp(x) + 1)*(np.exp(x)*x - 1)\n",
    "newton_method_stop2(0.3,f,fp,1e-5,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter      grad         root:(x,_)           root:(_,y)        interval length\n",
      "------------------------------------------------------------------------------\n",
      "  1     0.00217     -1.1786828328725436   1.279900e-04\n",
      "  2     0.00092     -1.2376200000887663   4.047965e-05      0.0589371672162227\n",
      "  3     0.00039     -1.2817913472216889   1.280496e-05      0.0441713471329226\n",
      "  4     0.00016     -1.3149065788863532   4.051027e-06      0.0331152316646643\n",
      "  5     0.00007     -1.3397374059706373   1.281674e-06      0.0248308270842841\n",
      "  6     0.00003     -1.3583581664428563   4.055124e-07      0.0186207604722191\n",
      "  7     0.00001     -1.3723227415318771   1.283036e-07      0.0139645750890207\n",
      "  8     0.00001     -1.3827957530364929   4.059552e-08      0.0104730115046159\n",
      "  9     0.00000     -1.3906503345627994   1.284458e-08      0.0078545815263065\n",
      " 10     0.00000     -1.3965411959453928   4.064088e-09      0.0058908613825934\n",
      " 11     0.00000     -1.4009593103716593   1.285900e-09      0.0044181144262665\n",
      " 12     0.00000     -1.4042728827302866   4.068661e-10      0.0033135723586273\n",
      " 13     0.00000     -1.4067580559450539   1.287349e-10      0.0024851732147673\n",
      " 14     0.00000     -1.4086219333745069   4.073242e-11      0.0018638774294530\n",
      " 15     0.00000     -1.4100198364844072   1.288791e-11      0.0013979031099003\n",
      " 16     0.00000     -1.4110682536052201   4.077849e-12      0.0010484171208129\n",
      " 17     0.00000     -1.4118545617307952   1.290190e-12      0.0007863081255750\n",
      " 18     0.00000     -1.4124442478610790   4.082290e-13      0.0005896861302839\n",
      " 19     0.00000     -1.4128864695578682   1.291189e-13      0.0004422216967892\n",
      " 20     0.00000     -1.4132179343758560   4.085621e-14      0.0003314648179877\n",
      " 21     0.00000     -1.4134663151760201   1.287859e-14      0.0002483808001641\n",
      " 22     0.00000     -1.4136515092306523   4.107825e-15      0.0001851940546322\n",
      " 23     0.00000     -1.4137903220434502   1.110223e-15      0.0001388128127979\n",
      " 24     0.00000     -1.4138781831526088   4.440892e-16      0.0000878611091586\n",
      " 25     0.00000     -1.4139488170922168   1.110223e-16      0.0000706339396079\n",
      " 26     0.00000     -1.4139847160008898   0.000000e+00      0.0000358989086731\n",
      " 27     0.00000     -1.4139847160008898   0.000000e+00      0.0000000000000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1.4139847160008898"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(b)\n",
    "f = lambda x: np.cos(x + 2**0.5) + x*(x/2 + 2**0.5)\n",
    "fp = lambda x: x - np.sin(x + 2**0.5) + 2**0.5\n",
    "newton_method_stop2(-1.1,f,fp,1e-5,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter      grad         root:(x,_)           root:(_,y)        interval length\n",
      "------------------------------------------------------------------------------\n",
      "  1   1670.46877      3.9281203817224708   9.240626e+01\n",
      "  2   707.45522      3.8728028181894754   2.925066e+01      0.0553175635329954\n",
      "  3   303.10091      3.8314565077979177   9.122787e+00      0.0413463103915577\n",
      "  4   131.11907      3.8013583241816207   2.809005e+00      0.0300981836162970\n",
      "  5    57.15513      3.7799350098217919   8.559359e-01      0.0214233143598288\n",
      "  6    25.05798      3.7649593487547013   2.587117e-01      0.0149756610670906\n",
      "  7    11.03217      3.7546348218974384   7.772826e-02      0.0103245268572629\n",
      "  8     4.87160      3.7475892211112494   2.325202e-02      0.0070456007861890\n",
      "  9     2.15568      3.7428162429994458   6.934561e-03      0.0047729781118035\n",
      " 10     0.95525      3.7395993586017480   2.063773e-03      0.0032168843976979\n",
      " 11     0.42371      3.7374388973757022   6.133084e-04      0.0021604612260457\n",
      " 12     0.18806      3.7359914253673323   1.820839e-04      0.0014474720083699\n",
      " 13     0.08351      3.7350232265386132   5.402294e-05      0.0009681988287191\n",
      " 14     0.03709      3.7343763202789830   1.602108e-05      0.0006469062596302\n",
      " 15     0.01648      3.7339444070597558   4.749832e-06      0.0004319132192272\n",
      " 16     0.00732      3.7336561778350950   1.407956e-06      0.0002882292246609\n",
      " 17     0.00325      3.7334638923629315   4.173198e-07      0.0001922854721634\n",
      " 18     0.00145      3.7333356307488743   1.236913e-07      0.0001282616140572\n",
      " 19     0.00064      3.7332500717343184   3.664172e-08      0.0000855590145559\n",
      " 20     0.00029      3.7331930094692956   1.079752e-08      0.0000570622650229\n",
      " 21     0.00013      3.7331551359148243   3.230525e-09      0.0000378735544713\n",
      " 22     0.00006      3.7331297169957813   9.313226e-10      0.0000254189190430\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.7331297169957813"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(c)\n",
    "f = lambda x: np.exp(3*x) - 27*x**6 + 27*(x**4)*np.exp(x) - 9*(x**2)*np.exp(2*x)\n",
    "fp = lambda x: 3*(np.exp(x) - 6*x)*(np.exp(x) - 3*x**2)**2\n",
    "newton_method_stop2(4,f,fp,1e-5,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If p is a root of $f(x) = 0$ with multiplicity $m$, then\n",
    "$$f(x) = g(x)(h(x) - h(p))^m \\mbox{ where } g(p) \\neq 0.$$\n",
    "\n",
    "This implies that\n",
    "\n",
    "$\\begin{align*}\n",
    "f'(x) &= g'(x)(h(x) - h(p))^m + mg(x)h'(x)(h(x) - h(p))^{m-1} \\\\\n",
    "&= (g'(x)(h(x) - h(p)) - mg(x)(h'(x))(h(x) - h(p)^{m-1}) \\\\\n",
    "&= g_1(x)(h(x) - h(p))^{m-1}.\n",
    "\\end{align*}$\n",
    "\n",
    "Therefore, $f^{(k)}(x) = g_k(x)(h(x) - h(p))^{m-k}$ for $1 \\leq k \\leq m-1$.\n",
    "\n",
    "Therefore, $f(p) = 0, f'(p) = 0, \\ldots, f^{(m-1)}(p) = 0.$\n",
    "\n",
    "According to Burden and Faires, quadratic convergence might not occur if $f(p) = 0$ and $f'(p) = 0$.\n",
    "\n",
    "If we let $g(x) = x - \\phi(x)f(x)$, then $g'(x) = 1 - \\phi'(x)f(x) -  \\phi(x)f'(x)$. However, if $f'(p) = 0$, then $g'(x) = 1$ for all function $\\phi$. $g'(x) \\neq 0$ implies linear convergence of any fixed point iteration scheme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Newton's method with multiplicity of root correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_method_stop2_mulcorrection(x0,f,fp,fpp,tol,N):\n",
    "    F = f(x0)\n",
    "    Fp = fp(x0)\n",
    "    Fpp = fpp(x0)\n",
    "    iteration = 1\n",
    "    print (\"iter      divisor         root:(x,_)           root:(_,y)        interval length\")\n",
    "    print (\"------------------------------------------------------------------------------\")\n",
    "    x = x0 - Fp*F/(Fp**2 - F*Fpp) #We run one iteration to get a x1 and (x0-x1) value.\n",
    "    x1 = x0 #x1 is the p_{n-1} value; sorry its a misnomer, I'm lazy to change it.\n",
    "    x0 = x\n",
    "    F = f(x0)\n",
    "    Fp = fp(x0)\n",
    "    Fpp = fpp(x0)\n",
    "    print('{:>3d}  {:> 10.5f}  {:> 22.16f}  {:>13.6e}'.format(1, Fp, x, np.abs(F), np.abs(x0-x1)))\n",
    "    iteration = iteration + 1\n",
    "    while (iteration<=N) & (np.abs(x0-x1)>np.abs(tol*x1)):\n",
    "        x = x0 - Fp*F/(Fp**2 - F*Fpp)\n",
    "        x1 = x0\n",
    "        x0 = x\n",
    "        F = f(x0)\n",
    "        Fp = fp(x0)\n",
    "        Fpp = fpp(x0)\n",
    "        print('{:>3d}  {:> 10.5f}  {:> 22.16f}  {:>13.6e}  {:> 22.16f}'.format(iteration, (Fp**2 - F*Fpp), x, np.abs(F),np.abs(x0-x1)))\n",
    "        iteration = iteration + 1\n",
    "    if np.abs(x-x0)<=np.abs(tol*x1):\n",
    "        return x0\n",
    "    else:\n",
    "        print(\"Method failed to converge. Try harder!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Bisection Method but with results stored in an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bisection_method_withresults(a,b,f,tol,N):\n",
    "    FA,FB = f(a), f(b)\n",
    "    results=[]\n",
    "    iteration = 1\n",
    "    if FA*FB<0:\n",
    "        print (\"iter      a           b            root:(x,_)           root:(_,y)\")\n",
    "        print (\"------------------------------------------------------------------\")\n",
    "        p = (a + b)/2\n",
    "        FP = f(p)\n",
    "        while (np.abs((b-a)/2)>tol) & (iteration <= N):\n",
    "            if FA*FP<0:\n",
    "                b=p\n",
    "                FB=FP\n",
    "            else:\n",
    "                a=p\n",
    "                FA=FP\n",
    "            p = (a+b)/2\n",
    "            FP = f(p)\n",
    "            print('{:>3d}  {:> 10.5f}  {:> 10.5f}  {:> 22.16f}  {:>13.6e}'.format(iteration, a, b, p, abs(FP)))\n",
    "            results.append(p)\n",
    "            iteration = iteration + 1\n",
    "        if np.abs((b-a)/2)>tol:\n",
    "            print(\"Method failed to converge\")\n",
    "        else:\n",
    "            return p, results\n",
    "    else:\n",
    "             print(\"Cannot ensure existence of root\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter      divisor         root:(x,_)           root:(_,y)        interval length\n",
      "------------------------------------------------------------------------------\n",
      "  1     0.08112      0.5838083972615007   6.779926e-04\n",
      "  2     0.00000      0.5671927362614900   6.004397e-09      0.0166156610000107\n",
      "  3     0.00000      0.5671432908508617   5.551115e-17      0.0000494454106283\n",
      "  4    -0.00000      0.5671432912844749   5.551115e-17      0.0000000004336133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5671432912844749"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(a)\n",
    "f = lambda x: x**2 - 2*x*np.exp(-x) + np.exp(-2*x)\n",
    "fp = lambda x: 2*np.exp(-2*x)*(np.exp(x) + 1)*(np.exp(x)*x - 1)\n",
    "fpp = lambda x: -2*np.exp(-x)*(x-2) + 4*np.exp(-2*x) + 2\n",
    "newton_method_stop2_mulcorrection(0.3,f,fp,fpp,1e-5,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter      divisor         root:(x,_)           root:(_,y)        interval length\n",
      "------------------------------------------------------------------------------\n",
      "  1     0.00000     -1.4131816691807593   4.718448e-14\n",
      "  2     0.00000     -1.4142085583550834   1.110223e-16      0.0010268891743241\n",
      "  3     0.00000     -1.4142085583550834   1.110223e-16      0.0000000000000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1.4142085583550834"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(b)\n",
    "f = lambda x: np.cos(x + 2**0.5) + x*(x/2 + 2**0.5)\n",
    "fp = lambda x: x - np.sin(x + 2**0.5) + 2**0.5\n",
    "fpp = lambda x: 1 - np.cos(x + 2**0.5)\n",
    "newton_method_stop2_mulcorrection(-1.1,f,fp,fpp,1e-5,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter      divisor         root:(x,_)           root:(_,y)        interval length\n",
      "------------------------------------------------------------------------------\n",
      "  1    65.06103      3.6720356968913230   1.403597e+00\n",
      "  2     0.02357      3.7295805255521182   3.100712e-04      0.0575448286607951\n",
      "  3     0.00000      3.7330677255408902   2.910383e-11      0.0034871999887720\n",
      "  4    -0.00000      3.7330640655685072   5.820766e-11      0.0000036599723829\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.7330640655685072"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(c)\n",
    "f = lambda x: np.exp(3*x) - 27*x**6 + 27*(x**4)*np.exp(x) - 9*(x**2)*np.exp(2*x)\n",
    "fp = lambda x: 3*(np.exp(x) - 6*x)*(np.exp(x) - 3*x**2)**2\n",
    "fpp = lambda x: 6*(np.exp(x) - 3*x**2)*(np.exp(x) - 6*x)**2 + 3*(np.exp(x) - 6)*(np.exp(x) - 3*x**2)**2\n",
    "newton_method_stop2_mulcorrection(4,f,fp,fpp,1e-5,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all three functions in Q1, Newton's Method with multiplicity of root correction results in faster convergence. In fact, for 1(c) and especially 1(b), the convergence appears to be faster than quadratic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the sequence $\\displaystyle\\left(p_{n+1} = p_n^3 \\mbox{ with } p_0 = 0.5\\right)_{n \\in \\mathbb{N}^0},$ i.e. $\\displaystyle\\left(2^{-3^n}\\right)_{n \\in \\mathbb{N}^0}$. This sequence converges to $0$.\n",
    "\n",
    "Let $\\alpha = 3$ in $\\displaystyle\\lim_{n\\rightarrow\\infty}\\frac{\\mid p_{n+1} - p \\mid}{\\mid p_{n} - p \\mid^\\alpha} = \\lambda$. $\\displaystyle\\lim_{n\\rightarrow\\infty}\\frac{\\mid p_{n+1}\\mid}{\\mid p_{n}\\mid^3} = \\lambda \\implies \\lim_{n\\rightarrow\\infty}\\frac{\\mid p_{n}\\mid^3}{\\mid p_{n}\\mid^3} = \\lambda \\implies \\lambda = 1$. \n",
    "Therefore, the sequence converges to $0$ with order $3$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error of the bisection algorithm is the length of the interval which is given by the sequence $\\displaystyle\\left(p_{n+1} = 0.5p_n \\mbox{ with } p_0 = \\mbox{some } \\mathbb{R}^+\\right)$, i.e. $\\displaystyle\\left(\\frac{a}{2^n} \\mbox{ for some } a\\in\\mathbb{R}^+\\right)_{n \\in \\mathbb{N}^0}$. This sequence converges to $0$.\n",
    "\n",
    "Let $\\alpha = 1$ in $\\displaystyle\\lim_{n\\rightarrow\\infty}\\frac{\\mid p_{n+1} - p \\mid}{\\mid p_{n} - p \\mid^\\alpha} = \\lambda$. $\\displaystyle\\lim_{n\\rightarrow\\infty}\\frac{\\mid p_{n+1}\\mid}{\\mid p_{n}\\mid} = \\lambda \\implies \\lim_{n\\rightarrow\\infty}\\frac{\\mid 0.5p_{n}\\mid}{\\mid p_{n}\\mid} = \\lambda \\implies \\lambda = 0.5$. \n",
    "Therefore, the sequence converges linearly to $0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter      a           b            root:(x,_)           root:(_,y)\n",
      "------------------------------------------------------------------\n",
      "  1     3.00000     4.00000      3.5000000000000000   4.801216e+01\n",
      "  2     3.50000     4.00000      3.7500000000000000   3.711999e-02\n",
      "  3     3.50000     3.75000      3.6250000000000000   6.828201e+00\n",
      "  4     3.62500     3.75000      3.6875000000000000   6.100351e-01\n",
      "  5     3.68750     3.75000      3.7187500000000000   2.067434e-02\n",
      "  6     3.71875     3.75000      3.7343750000000000   1.597218e-05\n",
      "  7     3.71875     3.73438      3.7265625000000000   1.987165e-03\n",
      "  8     3.72656     3.73438      3.7304687500000000   1.291051e-04\n",
      "  9     3.73047     3.73438      3.7324218750000000   2.071203e-06\n",
      " 10     3.73242     3.73438      3.7333984375000000   2.384768e-07\n",
      " 11     3.73242     3.73340      3.7329101562500000   3.518653e-08\n",
      " 12     3.73291     3.73340      3.7331542968750000   3.085006e-09\n",
      " 13     3.73291     3.73315      3.7330322265625000   7.566996e-10\n",
      " 14     3.73303     3.73315      3.7330932617187500   0.000000e+00\n",
      " 15     3.73309     3.73315      3.7331237792968750   6.693881e-10\n",
      " 16     3.73312     3.73315      3.7331390380859375   1.600711e-09\n",
      " 17     3.73314     3.73315      3.7331466674804688   2.270099e-09\n",
      " 18     3.73315     3.73315      3.7331504821777344   2.706656e-09\n",
      " 19     3.73315     3.73315      3.7331523895263672   2.881279e-09\n",
      " 20     3.73315     3.73315      3.7331533432006836   3.026798e-09\n",
      " 21     3.73315     3.73315      3.7331538200378418   3.055902e-09\n",
      " 22     3.73315     3.73315      3.7331540584564209   3.172318e-09\n",
      " 23     3.73315     3.73315      3.7331541776657104   3.143214e-09\n",
      " 24     3.73315     3.73315      3.7331542372703552   3.085006e-09\n",
      " 25     3.73315     3.73315      3.7331542670726776   3.143214e-09\n",
      " 26     3.73315     3.73315      3.7331542819738388   3.114110e-09\n",
      " 27     3.73315     3.73315      3.7331542894244194   3.143214e-09\n",
      " 28     3.73315     3.73315      3.7331542931497097   3.114110e-09\n",
      " 29     3.73315     3.73315      3.7331542950123549   3.085006e-09\n",
      " 30     3.73315     3.73315      3.7331542959436774   3.085006e-09\n",
      " 31     3.73315     3.73315      3.7331542964093387   3.114110e-09\n",
      " 32     3.73315     3.73315      3.7331542966421694   3.085006e-09\n",
      " 33     3.73315     3.73315      3.7331542967585847   3.143214e-09\n",
      " 34     3.73315     3.73315      3.7331542968167923   3.114110e-09\n",
      " 35     3.73315     3.73315      3.7331542968458962   3.114110e-09\n",
      " 36     3.73315     3.73315      3.7331542968604481   3.114110e-09\n",
      " 37     3.73315     3.73315      3.7331542968677240   3.143214e-09\n",
      " 38     3.73315     3.73315      3.7331542968713620   3.085006e-09\n",
      " 39     3.73315     3.73315      3.7331542968731810   3.172318e-09\n",
      " 40     3.73315     3.73315      3.7331542968740905   3.143214e-09\n",
      " 41     3.73315     3.73315      3.7331542968745453   3.055902e-09\n",
      " 42     3.73315     3.73315      3.7331542968747726   3.143214e-09\n",
      " 43     3.73315     3.73315      3.7331542968748863   3.172318e-09\n",
      " 44     3.73315     3.73315      3.7331542968749432   3.172318e-09\n",
      " 45     3.73315     3.73315      3.7331542968749716   3.085006e-09\n",
      " 46     3.73315     3.73315      3.7331542968749858   3.143214e-09\n",
      " 47     3.73315     3.73315      3.7331542968749929   3.143214e-09\n",
      " 48     3.73315     3.73315      3.7331542968749964   3.085006e-09\n",
      " 49     3.73315     3.73315      3.7331542968749982   3.143214e-09\n",
      " 50     3.73315     3.73315      3.7331542968749991   3.085006e-09\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.grid(b=None, which='major', axis='both', **kwargs)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = lambda x: np.exp(3*x) - 27*x**6 + 27*(x**4)*np.exp(x) - 9*(x**2)*np.exp(2*x)\n",
    "p, results = bisection_method_withresults(3,5,f,1e-15,100)\n",
    "plot=[[],[]]\n",
    "for i in range(0, len(results)-1):\n",
    "    plot[0].append(np.abs(results[i]-p))\n",
    "    plot[1].append(np.abs(results[i+1]-p))\n",
    "plt.loglog(plot[0],plot[1], '.') #Apart from a few anomalous plots, the convergence is linear.\n",
    "plt.grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose sequence $(p_n)$ converges to $p$ of order $\\alpha$ and $n$ is large. Therefore, $\\displaystyle\\frac{| p_{n+1} - p|}{| p_n - p|^\\alpha} \\approx \\lambda \\implies \\frac{| p_n - p|}{| p_{n-1} - p|^\\alpha} \\approx \\lambda$. \n",
    "\n",
    "$\\displaystyle\\frac{| p_n - p|}{| p_{n-1} - p|^\\alpha} \\approx \\lambda \\implies \\left(\\frac{1}{\\lambda}| p_n - p|\\right)^{1/\\alpha} \\approx | p_{n-1} - p|$.\n",
    "\n",
    "Given $| p_{n+1} - p| \\approx C | p_n - p|| p_{n-1} - p|$, we have $\\displaystyle| p_{n+1} - p| \\approx C\\left(\\frac{1}{\\lambda}\\right)^{1/\\alpha}|p_n - p|^{1/\\alpha}|p_n - p| \\implies \\frac{| p_{n+1} - p|}{| p_n - p|^{1+1/\\alpha}} \\approx C\\left(\\frac{1}{\\lambda}\\right)^{1/\\alpha}$.\n",
    "\n",
    "Since $\\displaystyle C\\left(\\frac{1}{\\lambda}\\right)^{1/\\alpha}$ is a positive constant, $\\displaystyle\\frac{1+\\alpha}{\\alpha} = \\alpha \\implies \\alpha^2 - \\alpha - 1 = 0 \\implies \\alpha = \\frac{1 + \\sqrt{5}}{2} \\approx 1.618$ since $\\alpha > 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accelerating Convergence: Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Newton's Method (with $|p_n - p_{n-1}| \\leq \\epsilon$ stopping criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_method_stop1(x0,f,fp,tol,N):\n",
    "    F = f(x0)\n",
    "    Fp = fp(x0)\n",
    "    results=[]\n",
    "    iteration = 1\n",
    "    print (\"iter      grad         root:(x,_)           root:(_,y)        interval length\")\n",
    "    print (\"------------------------------------------------------------------------------\")\n",
    "    x = (Fp*x0 - F)/Fp #We run one iteration to get a (x0-x1) value, though if we immediately get the root, we will just return it.\n",
    "    results.append(x)\n",
    "    x1 = x0 #x1 is the p_{n-1} value; sorry its a misnomer, I'm lazy to change it.\n",
    "    x0 = x\n",
    "    F = f(x0)\n",
    "    Fp = fp(x0)\n",
    "    print('{:>3d}  {:> 10.5f}  {:> 22.16f}  {:>13.6e}  {:> 22.16f}'.format(1, Fp, x, np.abs(F),np.abs(x0-x1)))\n",
    "    if np.abs(F)<=tol:\n",
    "        return x0\n",
    "    else:\n",
    "        iteration = iteration + 1\n",
    "        while (iteration<=N) & (np.abs(x0-x1)>tol):\n",
    "            x = (Fp*x0 - F)/Fp\n",
    "            results.append(x)\n",
    "            x1 = x0\n",
    "            x0 = x\n",
    "            F = f(x0)\n",
    "            Fp = fp(x0)\n",
    "            print('{:>3d}  {:> 10.5f}  {:> 22.16f}  {:>13.6e}  {:> 22.16f}'.format(iteration, Fp, x, np.abs(F),np.abs(x0-x1)))\n",
    "            iteration = iteration + 1\n",
    "        if np.abs(x-x0)<=tol:\n",
    "            return x0, results\n",
    "        else:\n",
    "            print(\"Method failed to converge. Try harder!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter      grad         root:(x,_)           root:(_,y)        interval length\n",
      "------------------------------------------------------------------------------\n",
      "  1     0.23802     -0.0511421365733425   9.211568e-03      0.0511421365733425\n",
      "  2     0.10164     -0.0898424758150268   2.886715e-03      0.0387003392416843\n",
      "  3     0.04388     -0.1182447360258248   8.915830e-04      0.0284022602107980\n",
      "  4     0.01910     -0.1385655958400078   2.721970e-04      0.0203208598141830\n",
      "  5     0.00837     -0.1528161929692974   8.237076e-05      0.0142505971292896\n",
      "  6     0.00368     -0.1626602525902589   2.476594e-05      0.0098440596209615\n",
      "  7     0.00163     -0.1693861756223201   7.412004e-06      0.0067259230320612\n",
      "  8     0.00072     -0.1739460644747723   2.211159e-06      0.0045598888524522\n",
      "  9     0.00032     -0.1770208137708657   6.581784e-07      0.0030747492960934\n",
      " 10     0.00014     -0.1790864552280062   1.956199e-07      0.0020656414571405\n",
      " 11     0.00006     -0.1804706766816483   5.808176e-08      0.0013842214536422\n",
      " 12     0.00003     -0.1813966891506640   1.723331e-08      0.0009260124690156\n",
      " 13     0.00001     -0.1820154613767330   5.110905e-09      0.0006187722260690\n",
      " 14     0.00001     -0.1824286147391486   1.515281e-09      0.0004131533624157\n",
      " 15     0.00000     -0.1827043349434589   4.491577e-10      0.0002757202043102\n",
      " 16     0.00000     -0.1828882751315548   1.331205e-10      0.0001839401880959\n"
     ]
    }
   ],
   "source": [
    "f = lambda x: np.exp(6*x) + 3*(np.log(2)**2)*np.exp(2*x) - np.log(8)*np.exp(4*x) - np.log(2)**3\n",
    "fp = lambda x: 6*np.exp(6*x) + 6*(np.log(2)**2)*np.exp(2*x) - 4*np.log(8)*np.exp(4*x)\n",
    "newton_method_stop1(0,f,fp,0.0002,100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aitken's Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter      grad         root:(x,_)           root:(_,y)        interval length\n",
      "------------------------------------------------------------------------------\n",
      "  1     0.23802     -0.0511421365733425   9.211568e-03      0.0511421365733425\n",
      "  2     0.10164     -0.0898424758150268   2.886715e-03      0.0387003392416843\n",
      "  3     0.04388     -0.1182447360258248   8.915830e-04      0.0284022602107980\n",
      "  4     0.01910     -0.1385655958400078   2.721970e-04      0.0203208598141830\n",
      "  5     0.00837     -0.1528161929692974   8.237076e-05      0.0142505971292896\n",
      "  6     0.00368     -0.1626602525902589   2.476594e-05      0.0098440596209615\n",
      "  7     0.00163     -0.1693861756223201   7.412004e-06      0.0067259230320612\n",
      "  8     0.00072     -0.1739460644747723   2.211159e-06      0.0045598888524522\n",
      "  9     0.00032     -0.1770208137708657   6.581784e-07      0.0030747492960934\n",
      " 10     0.00014     -0.1790864552280062   1.956199e-07      0.0020656414571405\n",
      " 11     0.00006     -0.1804706766816483   5.808176e-08      0.0013842214536422\n",
      " 12     0.00003     -0.1813966891506640   1.723331e-08      0.0009260124690156\n",
      " 13     0.00001     -0.1820154613767330   5.110905e-09      0.0006187722260690\n",
      " 14     0.00001     -0.1824286147391486   1.515281e-09      0.0004131533624157\n",
      " 15     0.00000     -0.1827043349434589   4.491577e-10      0.0002757202043102\n",
      " 16     0.00000     -0.1828882751315548   1.331205e-10      0.0001839401880959\n",
      "\n",
      "  0      -0.051142136573342        -0.064445431703108\n",
      "  1      -0.089842475815027        -0.094138710877246\n",
      "  2      -0.118244736025825        -0.119947151078497\n",
      "  3      -0.138565595840008        -0.139286918410616\n",
      "  4      -0.152816192969297        -0.153130056437536\n",
      "  5      -0.162660252590259        -0.162798389689639\n",
      "  6      -0.169386175622320        -0.169447284009083\n",
      "  7      -0.173946064474772        -0.173973161206561\n",
      "  8      -0.177020813770866        -0.177032842520221\n",
      "  9      -0.179086455228006        -0.179091797957426\n",
      " 10      -0.180470676681648        -0.180473050390800\n",
      " 11      -0.181396689150664        -0.181397743916850\n",
      " 12      -0.182015461376733        -0.182015930104172\n",
      " 13      -0.182428614739149        -0.182428823046690\n"
     ]
    }
   ],
   "source": [
    "f = lambda x: np.exp(6*x) + 3*(np.log(2)**2)*np.exp(2*x) - np.log(8)*np.exp(4*x) - np.log(2)**3\n",
    "fp = lambda x: 6*np.exp(6*x) + 6*(np.log(2)**2)*np.exp(2*x) - 4*np.log(8)*np.exp(4*x)\n",
    "p, results = newton_method_stop1(0,f,fp,0.0002,100)\n",
    "results_Atkin=np.zeros(len(results))\n",
    "print(\"\")\n",
    "for n in range(1,len(results)):\n",
    "    if n>=2:\n",
    "        results_Atkin[n-2] = results[n-2] - (results[n-1]-results[n-2])**2/(results[n]-2*results[n-1]-results[n-2])\n",
    "        print(\"%3d      % 3.15f        % 3.15f\" %(n-2,results[n-2],results_Atkin[n-2])) #There is almost no improvement in convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolation: Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Lagrange Polynomial Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L(xvals,kk,x):\n",
    "    value = np.ones(x.size)\n",
    "    n = xvals.size\n",
    "    for ii in range(0,n):\n",
    "        if ii != kk:\n",
    "            value *= (x-xvals[ii])/(xvals[kk]-xvals[ii])\n",
    "    return value\n",
    "    \n",
    "def p_Lagrange(xvals,yvals,x):\n",
    "    n = yvals.size\n",
    "    pLagrange = np.zeros(x.size)\n",
    "    for kk in range(0,n):\n",
    "        pLagrange += yvals[kk]*L(xvals,kk,x)\n",
    "    return pLagrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate = 0.898; Absolute Error = 2.347e-03\n"
     ]
    }
   ],
   "source": [
    "# 1(a)\n",
    "f = lambda x: np.cos(x)\n",
    "xvals = np.array([0, .6, .9])\n",
    "x = np.array([0.45])\n",
    "yvals = f(xvals)\n",
    "estimate = p_Lagrange(xvals,yvals,x)[0] #Estimate\n",
    "abs_error = np.abs(estimate - f(x[0])) #\n",
    "print('Estimate = {:<1.3f}; Absolute Error = {:<1.3e}'.format(estimate,abs_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate = 1.203; Absolute Error = 7.357e-04\n"
     ]
    }
   ],
   "source": [
    "# 1(b)\n",
    "f = lambda x: np.sqrt(1+x)\n",
    "xvals = np.array([0, .6, .9])\n",
    "x = np.array([0.45])\n",
    "yvals = f(xvals)\n",
    "estimate = p_Lagrange(xvals,yvals,x)[0] #Estimate\n",
    "abs_error = np.abs(estimate - f(x[0])) #\n",
    "print('Estimate = {:<1.3f}; Absolute Error = {:<1.3e}'.format(estimate,abs_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate = 0.368; Absolute Error = 3.273e-03\n"
     ]
    }
   ],
   "source": [
    "# 1(c)\n",
    "f = lambda x: np.log(np.abs(1+x))\n",
    "xvals = np.array([0, .6, .9])\n",
    "x = np.array([0.45])\n",
    "yvals = f(xvals)\n",
    "estimate = p_Lagrange(xvals,yvals,x)[0] #Estimate\n",
    "abs_error = np.abs(estimate - f(x[0])) #\n",
    "print('Estimate = {:<1.3f}; Absolute Error = {:<1.3e}'.format(estimate,abs_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate = 0.455; Absolute Error = 2.844e-02\n"
     ]
    }
   ],
   "source": [
    "# 1(d)\n",
    "f = lambda x: np.tan(x)\n",
    "xvals = np.array([0, .6, .9])\n",
    "x = np.array([0.45])\n",
    "yvals = f(xvals)\n",
    "estimate = p_Lagrange(xvals,yvals,x)[0] #Estimate\n",
    "abs_error = np.abs(estimate - f(x[0])) #\n",
    "print('Estimate = {:<1.3f}; Absolute Error = {:<1.3e}'.format(estimate,abs_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\displaystyle P'_n(x) = \\sum_{k=0}^n f(x_k)L'_{n,k}(x)$ since $f(x_k)$ is just a constant. We want to find a formula for $L'_{n,k}(x)$.\n",
    "\n",
    "$\\displaystyle\\ln(L_{n,k}(x)) = \\sum_{j=0,j\\neq k}^n \\ln\\frac{x - x_j}{x_k - x_j} \\implies \\frac{d}{dx}\\ln(L_{n,k}(x)) = \\frac{L'_{n,k}(x)}{L_{n,k}(x)} = \\sum_{j=0,j\\neq k}^n \\frac{1}{x_k - x_j}\\frac{x_k - x_j}{x - x_j} = \\sum_{j=0,j\\neq k}^n \\frac{1}{x - x_j}$.\n",
    "\n",
    "Therefore, $\\displaystyle L'_{n,k}(x) = L_{n,k}(x)\\left(\\sum_{j=0,j\\neq k}^n \\frac{1}{x - x_j}\\right)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L(xvals,kk,x):\n",
    "    value = np.ones(x.size)\n",
    "    n = xvals.size\n",
    "    for ii in range(0,n):\n",
    "        if ii != kk:\n",
    "            value *= (x-xvals[ii])/(xvals[kk]-xvals[ii])\n",
    "    return value\n",
    "\n",
    "def LpSum(xvals,kk,x):\n",
    "    lval = np.zeros(x.size)\n",
    "    n = xvals.size\n",
    "    for ii in range(0,n):\n",
    "        if ii != kk:\n",
    "            lval += 1/(x-xvals[ii])\n",
    "    return lval\n",
    "\n",
    "def p_LagrangeP(xvals,fvals,x):\n",
    "    n = fvals.size\n",
    "    pLagrange = np.zeros(x.size)\n",
    "    for kk in range(0,n):\n",
    "        pLagrange += fvals[kk]*L(xvals,kk,x)*LpSum(xvals,kk,x)\n",
    "    return pLagrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate = -0.420; Absolute Error = 1.453e-02\n"
     ]
    }
   ],
   "source": [
    "# 2(a)\n",
    "f = lambda x: np.cos(x)\n",
    "fp = lambda x: -np.sin(x)\n",
    "xvals = np.array([0, .6, .9])\n",
    "x = np.array([0.45])\n",
    "yvals = f(xvals)\n",
    "estimate = p_LagrangeP(xvals,yvals,x)[0] #Estimate\n",
    "abs_error = np.abs(estimate - fp(x[0])) #\n",
    "print('Estimate = {:<1.3f}; Absolute Error = {:<1.3e}'.format(estimate,abs_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate = 0.420; Absolute Error = 5.222e-03\n"
     ]
    }
   ],
   "source": [
    "# 2(b)\n",
    "f = lambda x: np.sqrt(1+x)\n",
    "fp = lambda x: 0.5*np.sqrt(1/(1+x))\n",
    "xvals = np.array([0, .6, .9])\n",
    "x = np.array([0.45])\n",
    "yvals = f(xvals)\n",
    "estimate = p_LagrangeP(xvals,yvals,x)[0] #Estimate\n",
    "abs_error = np.abs(estimate - fp(x[0])) #\n",
    "print('Estimate = {:<1.3f}; Absolute Error = {:<1.3e}'.format(estimate,abs_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate = 0.713; Absolute Error = 2.352e-02\n"
     ]
    }
   ],
   "source": [
    "# 2(c)\n",
    "f = lambda x: np.log(np.abs(1+x))\n",
    "fp = lambda x: 1/(1+x)\n",
    "xvals = np.array([0, .6, .9])\n",
    "x = np.array([0.45])\n",
    "yvals = f(xvals)\n",
    "estimate = p_LagrangeP(xvals,yvals,x)[0] #Estimate\n",
    "abs_error = np.abs(estimate - fp(x[0])) #\n",
    "print('Estimate = {:<1.3f}; Absolute Error = {:<1.3e}'.format(estimate,abs_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate = 1.400; Absolute Error = 1.668e-01\n"
     ]
    }
   ],
   "source": [
    "# 2(d)\n",
    "f = lambda x: np.tan(x)\n",
    "fp = lambda x: 1/(np.cos(x)**2)\n",
    "xvals = np.array([0, .6, .9])\n",
    "x = np.array([0.45])\n",
    "yvals = f(xvals)\n",
    "estimate = p_LagrangeP(xvals,yvals,x)[0] #Estimate\n",
    "abs_error = np.abs(estimate - fp(x[0])) #\n",
    "print('Estimate = {:<1.3f}; Absolute Error = {:<1.3e}'.format(estimate,abs_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for Cubic Spline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cubic_spline_coeffs(xvals,yvals): #This gives the coeffs for the LAGRANGE POLYNOMIAL, not the standard polynomial.\n",
    "\n",
    "    n = xvals.size - 1\n",
    "    h = xvals[1:]-xvals[0:-1]\n",
    "\n",
    "    d0 = np.hstack([1,2*(h[0:-1]+h[1:]),1])\n",
    "    d1 = np.hstack([0,h[1:]])\n",
    "    dm1 = np.hstack([h[0:-1],0])\n",
    "    # create the \"A\" matrix by using the np.diag command\n",
    "    A = np.diag(d0) + np.diag(d1,1)+ np.diag(dm1,-1)\n",
    "\n",
    "    \n",
    "    # create the right-hand-side of A*x = b\n",
    "    # recall that a_j = y_j\n",
    "    aVec = yvals\n",
    "    rhs = np.hstack([0,(3./h[1:])*(aVec[2:]-aVec[1:-1])-(3/h[0:-1])*(aVec[1:-1]-aVec[0:-2]),0])\n",
    "    \n",
    "    # use the linalg.solve command to solve Ax = b  \n",
    "    cVec = np.linalg.solve(A,rhs)\n",
    "\n",
    "    \n",
    "    # use the remaining formula to determine d_j and b_j\n",
    "    dVec = (cVec[1:]-cVec[0:-1])/(3*h)\n",
    "    bVec = 1/h*(aVec[1:] - aVec[0:-1]) - h/3*(2*cVec[0:-1]+cVec[1:])\n",
    "    \n",
    "    # stack all of the coefficients into a matrix so that the coefficients are in the form \n",
    "    #            a_0, a_1, ...\n",
    "    #            b_0, b_1, ...\n",
    "    #            c_0, c_1, ...\n",
    "    #            d_0, d_1, ...\n",
    "    \n",
    "    SCoeffs = np.vstack([aVec[0:n], bVec[0:n], cVec[0:n], dVec[0:n]])\n",
    "    return SCoeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cubic_spline_f(x, coeffs, xvals):\n",
    "    n = len(coeffs[0])\n",
    "    ans = 0\n",
    "    for ii in range(0,4):\n",
    "        for jj in range(0,n):\n",
    "            ans += coeffs[ii][jj]*((x-xvals[jj])**ii)*((xvals[jj]<x) and (x<=xvals[jj+1]))\n",
    "    return ans\n",
    "\n",
    "def cubic_spline_fp(x, coeffs, xvals):\n",
    "    n = len(coeffs[0])\n",
    "    ans = 0\n",
    "    for ii in range(1,4):\n",
    "        for jj in range(0,n):\n",
    "            ans += coeffs[ii][jj]*ii*((x-xvals[jj])**(ii-1))*((xvals[jj]<x) and (x<=xvals[jj+1]))\n",
    "    return ans\n",
    "\n",
    "def cubic_spline_fpp(x, coeffs, xvals):\n",
    "    n = len(coeffs[0])\n",
    "    ans = 0\n",
    "    for ii in range(2,4):\n",
    "        for jj in range(0,n):\n",
    "            ans += coeffs[ii][jj]*ii*(ii-1)*((x-xvals[jj])**(ii-2))*((xvals[jj]<x) and (x<=xvals[jj+1]))\n",
    "    return ans\n",
    "\n",
    "def cubic_spline_f_integrate(coeffs, xvals): #xvals demarcate the integration; coeffs must contain ONLY the coeffs involved in the integration.\n",
    "    n = len(coeffs[0])\n",
    "    ans = 0\n",
    "    for kk in range(0,n):\n",
    "        x_l,x_u = xvals[kk], xvals[kk+1]\n",
    "        for ii in range(0,4):\n",
    "            for jj in range(0,n):\n",
    "                ans += coeffs[ii][jj]*(1/(ii+1))*((x_u-xvals[kk+1])**(ii+1)) - coeffs[ii][jj]*(1/(ii+1))*((x_l-xvals[kk])**(ii+1))\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using coefficients from cubic_spline_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integration over [0,1]; actual value = 0\n",
      "0.0\n",
      "\n",
      "\n",
      "f value comparison of spline vs actual\n",
      "6.123233995736766e-17\n",
      "9.71445146547012e-17\n",
      "3.591217469733354e-17\n",
      "\n",
      "\n",
      "fp value comparison of spline vs actual\n",
      "-3.2426406871192848\n",
      "-3.141592653589793\n",
      "0.10104803352949165\n",
      "\n",
      "\n",
      "fpp value comparison of spline vs actual\n",
      "-3.552713678800501e-15\n",
      "-6.043389719322356e-16\n",
      "2.9483747068682654e-15\n"
     ]
    }
   ],
   "source": [
    "fp_actual = lambda x: -pi*np.sin(pi*x)\n",
    "fpp_actual = lambda x: -(pi**2)*np.cos(pi*x)\n",
    "\n",
    "f_actual = lambda x: np.cos(np.pi*x)\n",
    "xvals = np.array([0,0.25,0.5,0.75,1])\n",
    "yvals = f_actual(xvals)\n",
    "coeffs = cubic_spline_coeffs(xvals,yvals)\n",
    "\n",
    "print(\"Integration over [0,1]; actual value = 0\")\n",
    "print(cubic_spline_f_integrate(coeffs, xvals))\n",
    "print()\n",
    "print()\n",
    "print(\"f value comparison of spline vs actual\")\n",
    "print(f_actual(0.5))\n",
    "print(cubic_spline_f(0.5,coeffs,xvals))\n",
    "print(np.abs(cubic_spline_f(0.5,coeffs,xvals) - f_actual(0.5)))\n",
    "print()\n",
    "print()\n",
    "print(\"fp value comparison of spline vs actual\")\n",
    "print(cubic_spline_fp(0.5,coeffs,xvals))\n",
    "print(fp_actual(0.5))\n",
    "print(np.abs(cubic_spline_fp(0.5,coeffs,xvals) - fp_actual(0.5)))\n",
    "print()\n",
    "print()\n",
    "print(\"fpp value comparison of spline vs actual\")\n",
    "print(cubic_spline_fpp(0.5,coeffs, xvals))\n",
    "print(fpp_actual(0.5))\n",
    "print(np.abs(cubic_spline_fpp(0.5,coeffs, xvals) - fpp_actual(0.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot of the cubic spline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2523f8b8b70>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xplot = np.linspace(0.01,1,100)\n",
    "CSyplot=[]\n",
    "actualyplot = f_actual(xplot)\n",
    "for x in xplot:\n",
    "    CSyplot.append(cubic_spline_f(x,coeffs,xvals))\n",
    "plt.plot(xplot, CSyplot)\n",
    "plt.plot(xplot, actualyplot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
